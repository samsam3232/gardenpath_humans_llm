{"meta-llama/Llama-3.2-1B": 0.8333333333333334, "meta-llama/Llama-3.2-1B-Instruct": 0.8333333333333334, "meta-llama/Llama-3.2-3B": 0.8333333333333334, "meta-llama/Llama-3.2-3B-Instruct": 0.8333333333333334, "meta-llama/Llama-3.2-11B-Vision": 0.8333333333333334, "meta-llama/Llama-3.2-11B-Vision-Instruct": 0.8333333333333334, "meta-llama/Llama-3.1-8B": 0.8333333333333334, "meta-llama/Llama-3.1-8B-Instruct": 1.0, "meta-llama/Llama-2-7b-chat-hf": 0.8333333333333334, "meta-llama/Llama-2-13b-chat-hf": 0.8333333333333334, "Qwen/Qwen2.5-0.5B": 0.8333333333333334, "Qwen/Qwen2.5-0.5B-Instruct": 0.6666666666666666, "Qwen/Qwen2.5-1.5B": 0.8333333333333334, "Qwen/Qwen2.5-3B": 0.8333333333333334, "Qwen/Qwen2.5-3B-Instruct": 1.0, "Qwen/Qwen2.5-7B": 0.8333333333333334, "Qwen/Qwen2.5-7B-Instruct": 1.0, "Qwen/Qwen2.5-14B": 0.8333333333333334, "Qwen/Qwen2.5-14B-Instruct": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step1454000-tokens3048B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step917000-tokens1922B": 0.6666666666666666, "allenai/OLMo-1B-0724-hf_step827000-tokens1733B": 0.5, "allenai/OLMo-1B-0724-hf_step738000-tokens1547B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step648000-tokens1358B": 0.6666666666666666, "allenai/OLMo-1B-0724-hf_step558000-tokens1169B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step468000-tokens981B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step379000-tokens794B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step289000-tokens605B": 0.5, "allenai/OLMo-1B-0724-hf_step20000-tokens41B": 0.5, "allenai/OLMo-1B-0724-hf_step1399000-tokens2932B": 0.6666666666666666, "allenai/OLMo-1B-0724-hf_step1308000-tokens2742B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step1218000-tokens2553B": 0.6666666666666666, "allenai/OLMo-1B-0724-hf_step1128000-tokens2364B": 0.8333333333333334, "allenai/OLMo-1B-0724-hf_step1038000-tokens2176B": 0.6666666666666666, "allenai/OLMo-7B-0724-hf_step650650-tokens2729B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step647650-tokens2716B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step582000-tokens2441B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step519000-tokens2176B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step458000-tokens1920B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step395000-tokens1656B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step330000-tokens1384B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step26500-tokens111B": 0.16666666666666666, "allenai/OLMo-7B-0724-hf_step2000-tokens8B": 0.3333333333333333, "allenai/OLMo-7B-0724-hf_step143000-tokens599B": 0.8333333333333334, "allenai/OLMo-7B-0724-hf_step106500-tokens446B": 0.8333333333333334, "lmsys/vicuna-13b-v1.5": 0.8333333333333334, "lmsys/vicuna-7b-v1.5": 1.0, "google/gemma-2-2b": 0.8333333333333334, "google/gemma-2-2b-it": 0.8333333333333334, "google/gemma-2-9b": 1.0, "google/gemma-2-9b-it": 1.0, "meta-llama/Llama-3.1-70B": 0.6666666666666666, "meta-llama/Llama-3.1-70B-Instruct": 0.6666666666666666, "meta-llama/Meta-Llama-3-70B": 0.6666666666666666, "meta-llama/Llama-2-70b-hf": 1.0, "meta-llama/Llama-2-70b-chat-hf": 1.0, "Qwen/Qwen2.5-32B": 0.8333333333333334, "Qwen/Qwen2.5-32B-Instruct": 0.8333333333333334, "Qwen/Qwen2.5-72B": 0.6666666666666666, "Qwen/Qwen2.5-72B-Instruct": 0.8333333333333334, "gpt-4": 0.8333333333333334, "gpt-4-turbo": 0.8333333333333334, "gpt-4o": 0.8333333333333334, "gpt-4o-mini": 1.0, "o1-mini": 1.0, "o1-preview": 0.6666666666666666}