{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samuelamouyal/PycharmProjects/reading_comprehension_research\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/samuelamouyal/PycharmProjects/reading_comprehension_research/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.stats import pearsonr, zscore, kendalltau, spearmanr, rankdata\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from math import ceil, fabs\n",
    "\n",
    "\n",
    "df_llm = pd.read_csv('experiments/gardenpath_10_24/results/llm_results/averaged_all.csv')\n",
    "df_llm_distr = pd.read_csv('experiments/gardenpath_10_24/results/llm_results/all_results.csv')\n",
    "df_humans = pd.read_csv('experiments/gardenpath_10_24/results/human_results/sampled_results.csv')\n",
    "\n",
    "with open('experiments/gardenpath_10_24/analysis/data/families.json', 'r') as f:\n",
    "    families = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We filtered 35 models out of 188 models\n"
     ]
    }
   ],
   "source": [
    "accuracy_df = df_llm.groupby(['model', 'quest_type']).agg(\n",
    "    avg_accuracy=('avg_correct', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the data to have quest_type as columns\n",
    "pivoted_accuracy_df = accuracy_df.pivot(index='model', columns='quest_type', values='avg_accuracy').reset_index()\n",
    "\n",
    "# Step 4: Filter models based on accuracy conditions\n",
    "def condition(row):\n",
    "    return (row['simple_question'] - row['GP_question']) >= 0.05\n",
    "\n",
    "filtered_models_accuracy = pivoted_accuracy_df[~pivoted_accuracy_df.apply(condition, axis=1)]['model'].unique()\n",
    "df_llm = df_llm[~df_llm['model'].isin(filtered_models_accuracy)]\n",
    "\n",
    "print(f\"We filtered {len(filtered_models_accuracy)} models out of {len(df_llm['model'].unique()) + len(filtered_models_accuracy)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm = df_llm[df_llm['quest_type'] == 'GP_question']\n",
    "df_humans = df_humans[df_humans['quest_type'] == 'GP_question']\n",
    "df_llm_distr = df_llm_distr[df_llm_distr['quest_type'] == 'GP_question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average accuracy and standard error for each combination of ManipulationType and SentenceType\n",
    "avg_accuracy_humans = df_humans.groupby(['ManipulationType', 'SentenceType']).correct.mean().reset_index(name='correct_mean')\n",
    "std_error_humans = df_humans.groupby(['ManipulationType', 'SentenceType']).correct.sem().reset_index(name='correct_sem')\n",
    "avg_accuracy_humans = avg_accuracy_humans.merge(std_error_humans, on=['ManipulationType', 'SentenceType'])\n",
    "avg_accuracy_humans['model'] = 'Human'\n",
    "\n",
    "\n",
    "df_gemma = df_llm_distr[df_llm_distr['model'] == 'google/gemma-2-9b']\n",
    "avg_accuracy_gemma = df_gemma.groupby(['ManipulationType', 'SentenceType']).correct.mean().reset_index(name='correct_mean')\n",
    "std_error_gemma = df_gemma.groupby(['ManipulationType', 'SentenceType']).correct.sem().reset_index(name='correct_sem')\n",
    "avg_accuracy_gemma = avg_accuracy_gemma.merge(std_error_gemma, on=['ManipulationType', 'SentenceType'])\n",
    "avg_accuracy_gemma['model'] = 'Gemma-2-9B'\n",
    "\n",
    "avg_accuracy = pd.concat([avg_accuracy_humans, avg_accuracy_gemma])\n",
    "avg_accuracy['text_position'] = avg_accuracy['correct_mean'] + avg_accuracy['correct_sem'] + 0.02\n",
    "avg_accuracy['manip'] = avg_accuracy['ManipulationType'].map({'prob': 'Plausible', 'improb': 'Implausible', 'reflexive': 'Reflexive'}).reset_index(drop=True)\n",
    "avg_accuracy['Sentence type'] = avg_accuracy['SentenceType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "error_y": {
          "array": [
           0.023577574185109522,
           0.016042507257259784,
           0.02975839289899901
          ]
         },
         "hovertemplate": "Sentence type=GP<br>=Human<br>manip=%{x}<br>correct_mean=%{y}<extra></extra>",
         "legendgroup": "GP",
         "marker": {
          "color": "#E69F00",
          "pattern": {
           "shape": ""
          }
         },
         "name": "GP",
         "offsetgroup": "GP",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Implausible",
          "Plausible",
          "Reflexive"
         ],
         "xaxis": "x",
         "y": [
          0.48,
          0.13333333333333333,
          0.30416666666666664
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "error_y": {
          "array": [
           0.010770722084597263,
           0.006348006074484366,
           0.010736136409635786
          ]
         },
         "hovertemplate": "Sentence type=GP<br>=Gemma-2-9B<br>manip=%{x}<br>correct_mean=%{y}<extra></extra>",
         "legendgroup": "GP",
         "marker": {
          "color": "#E69F00",
          "pattern": {
           "shape": ""
          }
         },
         "name": "GP",
         "offsetgroup": "GP",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Implausible",
          "Plausible",
          "Reflexive"
         ],
         "xaxis": "x2",
         "y": [
          0.3642399738682461,
          0.14933856814475763,
          0.20315592207564673
         ],
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "error_y": {
          "array": [
           0.02342594834108722,
           0.018798055175614264,
           0.03109532852482742
          ]
         },
         "hovertemplate": "Sentence type=nonGP<br>=Human<br>manip=%{x}<br>correct_mean=%{y}<extra></extra>",
         "legendgroup": "nonGP",
         "marker": {
          "color": "#56B4E9",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "nonGP",
         "offsetgroup": "nonGP",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Implausible",
          "Plausible",
          "Reflexive"
         ],
         "xaxis": "x",
         "y": [
          0.56,
          0.19777777777777777,
          0.6375
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "error_y": {
          "array": [
           0.010510745576621903,
           0.008449467393940414,
           0.01239083151358422
          ]
         },
         "hovertemplate": "Sentence type=nonGP<br>=Gemma-2-9B<br>manip=%{x}<br>correct_mean=%{y}<extra></extra>",
         "legendgroup": "nonGP",
         "marker": {
          "color": "#56B4E9",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "nonGP",
         "offsetgroup": "nonGP",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "type": "bar",
         "x": [
          "Implausible",
          "Plausible",
          "Reflexive"
         ],
         "xaxis": "x2",
         "y": [
          0.5496612321514495,
          0.2238674259465954,
          0.46154075024297336
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "black",
           "size": 20
          },
          "showarrow": false,
          "text": "Human",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": -0.14,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "color": "black",
           "size": 20
          },
          "showarrow": false,
          "text": "Gemma-2-9B",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": -0.14,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.480",
          "x": 0.8,
          "xref": "x",
          "y": 0.5235775741851095,
          "yref": "y"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.560",
          "x": 1.2,
          "xref": "x",
          "y": 0.6034259483410873,
          "yref": "y"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.133",
          "x": -0.2,
          "xref": "x",
          "y": 0.1693758405905931,
          "yref": "y"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.198",
          "x": 0.2,
          "xref": "x",
          "y": 0.23657583295339202,
          "yref": "y"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.304",
          "x": 1.8,
          "xref": "x",
          "y": 0.35392505956566567,
          "yref": "y"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.637",
          "x": 2.2,
          "xref": "x",
          "y": 0.6885953285248274,
          "yref": "y"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.364",
          "x": 0.8,
          "xref": "x2",
          "y": 0.3950106959528434,
          "yref": "y2"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.550",
          "x": 1.2,
          "xref": "x2",
          "y": 0.5801719777280714,
          "yref": "y2"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.149",
          "x": -0.2,
          "xref": "x2",
          "y": 0.17568657421924197,
          "yref": "y2"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.224",
          "x": 0.2,
          "xref": "x2",
          "y": 0.2523168933405358,
          "yref": "y2"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.203",
          "x": 1.8,
          "xref": "x2",
          "y": 0.2338920584852825,
          "yref": "y2"
         },
         {
          "font": {
           "color": "black",
           "size": 18
          },
          "showarrow": false,
          "text": "0.462",
          "x": 2.2,
          "xref": "x2",
          "y": 0.4939315817565576,
          "yref": "y2"
         }
        ],
        "barmode": "group",
        "font": {
         "color": "black",
         "family": "American Typewriter",
         "size": 15
        },
        "height": 500,
        "legend": {
         "font": {
          "color": "black",
          "family": "American Typewriter",
          "size": 15
         },
         "orientation": "h",
         "title": {
          "text": "Sentence type"
         },
         "tracegroupgap": 0,
         "x": 0.5,
         "xanchor": "center",
         "y": -0.23,
         "yanchor": "bottom"
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "categoryarray": [
          "Plausible",
          "Implausible",
          "Reflexive"
         ],
         "categoryorder": "array",
         "domain": [
          0,
          0.475
         ],
         "tickfont": {
          "color": "black",
          "size": 18
         },
         "title": {
          "text": ""
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "categoryarray": [
          "Plausible",
          "Implausible",
          "Reflexive"
         ],
         "categoryorder": "array",
         "domain": [
          0.525,
          1
         ],
         "matches": "x",
         "tickfont": {
          "color": "black",
          "size": 18
         },
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Accuracy"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          1
         ],
         "matches": "y",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.bar(\n",
    "    avg_accuracy,\n",
    "    x='manip',\n",
    "    y='correct_mean',\n",
    "    color='Sentence type',\n",
    "    pattern_shape=\"Sentence type\",\n",
    "    barmode='group',\n",
    "    error_y='correct_sem',\n",
    "    category_orders={\"manip\": [\"Plausible\", \"Implausible\", \"Reflexive\"]},\n",
    "    color_discrete_sequence=['#E69F00', '#56B4E9'],\n",
    "    facet_col='model',\n",
    "    facet_col_spacing=0.05,  # Adjust spacing between models\n",
    "    labels={'model': ''}\n",
    ")\n",
    "\n",
    "# Update layout for the custom font and legend\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Arial\",\n",
    "        color=\"black\",\n",
    "        size=15\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=-0.23,\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        font=dict(\n",
    "            family=\"American Typewriter\",\n",
    "            color=\"black\",\n",
    "            size=15\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=20, color=\"black\"), y=-0.14, yanchor='bottom'))\n",
    "\n",
    "\n",
    "x_pos = [0.80, 1.20, -0.2, 0.2, 1.80, 2.20, 0.80, 1.20, -0.2, 0.2, 1.80, 2.20]\n",
    "# Add custom text annotations\n",
    "for i in range(avg_accuracy.shape[0]):\n",
    "    row = avg_accuracy.iloc[i]\n",
    "    fig.add_annotation(\n",
    "        x=x_pos[i],\n",
    "        y=row['text_position'],\n",
    "        text=f\"{row['correct_mean']:.3f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color='black', size=18),\n",
    "        col=2 if row['model'] == 'Gemma-2-9B' else 1,\n",
    "        row=1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(title='Accuracy'),\n",
    "    xaxis_title = \"\",\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.update_xaxes(tickfont=dict(size=18, color=\"black\"), title_text=\"\")\n",
    "\n",
    "fig.update_layout(font=dict(family=\"American Typewriter\"))\n",
    "fig.write_image('experiments/gardenpath_10_24/analysis/plots/humans_next_llm.pdf')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ManipulationType</th>\n",
       "      <th>SentenceType</th>\n",
       "      <th>correct_mean</th>\n",
       "      <th>partial_mean</th>\n",
       "      <th>correct_text_position</th>\n",
       "      <th>partial_text_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plausible</td>\n",
       "      <td>GP</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plausible</td>\n",
       "      <td>nonGP</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.113333</td>\n",
       "      <td>0.735556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Implausible</td>\n",
       "      <td>GP</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Implausible</td>\n",
       "      <td>nonGP</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.602222</td>\n",
       "      <td>0.157778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reflexive</td>\n",
       "      <td>GP</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reflexive</td>\n",
       "      <td>nonGP</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.521667</td>\n",
       "      <td>0.188333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ManipulationType SentenceType  correct_mean  partial_mean  \\\n",
       "2        Plausible           GP      0.066667      0.800000   \n",
       "3        Plausible        nonGP      0.133333      0.755556   \n",
       "0      Implausible           GP      0.377778      0.400000   \n",
       "1      Implausible        nonGP      0.622222      0.177778   \n",
       "4        Reflexive           GP      0.125000      0.750000   \n",
       "5        Reflexive        nonGP      0.541667      0.208333   \n",
       "\n",
       "   correct_text_position  partial_text_position  \n",
       "2               0.046667               0.780000  \n",
       "3               0.113333               0.735556  \n",
       "0               0.357778               0.380000  \n",
       "1               0.602222               0.157778  \n",
       "4               0.105000               0.730000  \n",
       "5               0.521667               0.188333  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drawings = pd.read_csv('/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/experiments/gardenpath_10_24/analysis/classification_progress.csv')\n",
    "df_drawings['ManipulationType'] = df_drawings['sent_type'].map(lambda x: x.split('_')[-1])\n",
    "df_drawings['ManipulationType'] = df_drawings['ManipulationType'].map({'prob': 'Plausible', 'improb': 'Implausible', 'reflexive': 'Reflexive'})\n",
    "df_drawings['SentenceType'] = df_drawings['sent_type'].map(lambda x: x.split('_')[0])\n",
    "df_drawings['correct'] = df_drawings['classification'] == 'correctly understood'\n",
    "df_drawings['partial'] = df_drawings['classification'] == 'partial misunderstanding'\n",
    "df_drawings['correct'] = df_drawings['correct'].astype(int)\n",
    "df_drawings['partial'] = df_drawings['partial'].astype(int)\n",
    "\n",
    "avg_accuracy_drawings = df_drawings.groupby(['ManipulationType', 'SentenceType']).correct.mean().reset_index(name='correct_mean')\n",
    "avg_misinterpretation = df_drawings.groupby(['ManipulationType', 'SentenceType']).partial.mean().reset_index(name='partial_mean')\n",
    "avg_accuracy_drawings = avg_accuracy_drawings.merge(avg_misinterpretation, on=['ManipulationType', 'SentenceType'])\n",
    "avg_accuracy_drawings['correct_text_position'] = avg_accuracy_drawings['correct_mean'] - 0.02\n",
    "avg_accuracy_drawings['partial_text_position'] = avg_accuracy_drawings['partial_mean'] - 0.02\n",
    "\n",
    "category_order = ['Plausible', 'Implausible', 'Reflexive']\n",
    "avg_accuracy_drawings['ManipulationType'] = pd.Categorical(\n",
    "    avg_accuracy_drawings['ManipulationType'],\n",
    "    categories=category_order,\n",
    "    ordered=True\n",
    ")\n",
    "avg_accuracy_drawings.sort_values('ManipulationType', inplace=True)\n",
    "avg_accuracy_drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#E69F00",
          "pattern": {
           "shape": ""
          }
         },
         "name": "GP (correct)",
         "type": "bar",
         "x": [
          "Plausible",
          "Implausible",
          "Reflexive"
         ],
         "y": [
          0.06666666666666667,
          0.37777777777777777,
          0.125
         ]
        },
        {
         "marker": {
          "color": "#F8E1B8",
          "pattern": {
           "shape": ""
          }
         },
         "name": "GP (partial)",
         "type": "bar",
         "x": [
          "Plausible",
          "Implausible",
          "Reflexive"
         ],
         "y": [
          0.8,
          0.4,
          0.75
         ]
        },
        {
         "marker": {
          "color": "#56B4E9",
          "pattern": {
           "shape": "x"
          }
         },
         "name": "nonGP (correct)",
         "type": "bar",
         "x": [
          "Plausible",
          "Implausible",
          "Reflexive"
         ],
         "y": [
          0.13333333333333333,
          0.6222222222222222,
          0.5416666666666666
         ]
        },
        {
         "marker": {
          "color": "#B0DFF8",
          "pattern": {
           "shape": "x"
          }
         },
         "name": "nonGP (partial)",
         "type": "bar",
         "x": [
          "Plausible",
          "Implausible",
          "Reflexive"
         ],
         "y": [
          0.7555555555555555,
          0.17777777777777778,
          0.20833333333333334
         ]
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.067",
          "x": -0.3,
          "y": 0.08666666666666667
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.800",
          "x": -0.09999999999999998,
          "y": 0.8200000000000001
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.133",
          "x": 0.1,
          "y": 0.15333333333333332
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.756",
          "x": 0.30000000000000004,
          "y": 0.7755555555555556
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.378",
          "x": 0.7,
          "y": 0.39777777777777773
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.400",
          "x": 0.8999999999999999,
          "y": 0.42
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.622",
          "x": 1.1,
          "y": 0.6422222222222222
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.178",
          "x": 1.3,
          "y": 0.1977777777777778
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.125",
          "x": 1.7,
          "y": 0.145
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.750",
          "x": 1.9,
          "y": 0.77
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.542",
          "x": 2.1,
          "y": 0.5616666666666666
         },
         {
          "font": {
           "color": "black",
           "size": 12
          },
          "showarrow": false,
          "text": "0.208",
          "x": 2.3000000000000003,
          "y": 0.22833333333333336
         }
        ],
        "font": {
         "color": "black",
         "family": "Arial",
         "size": 15
        },
        "height": 500,
        "legend": {
         "font": {
          "color": "black",
          "family": "American Typewriter",
          "size": 16
         },
         "orientation": "h",
         "x": 0.5,
         "xanchor": "center",
         "y": -0.2,
         "yanchor": "bottom"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": ""
         }
        },
        "yaxis": {
         "title": {
          "text": "Proportion"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define colors and patterns\n",
    "colors = {\n",
    "    'GP': ['#E69F00', '#F8E1B8'],       # Dark and light shades for GP\n",
    "    'nonGP': ['#56B4E9', '#B0DFF8'],    # Dark and light shades for nonGP\n",
    "}\n",
    "patterns = {\n",
    "    'GP': '',                 # Solid for GP bars\n",
    "    'nonGP': 'x'             # Cross-hatch for nonGP bars\n",
    "}\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars for GP and nonGP\n",
    "for sentence_type in ['GP', 'nonGP']:\n",
    "    # Correct Mean\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=avg_accuracy_drawings[avg_accuracy_drawings['SentenceType'] == sentence_type]['ManipulationType'],\n",
    "        y=avg_accuracy_drawings[avg_accuracy_drawings['SentenceType'] == sentence_type]['correct_mean'],\n",
    "        name=f'{sentence_type} (correct)',\n",
    "        marker_color=colors[sentence_type][0],  # Darker shade for correct_mean\n",
    "        marker_pattern_shape=patterns[sentence_type]\n",
    "    ))\n",
    "    \n",
    "    # Partial Mean\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=avg_accuracy_drawings[avg_accuracy_drawings['SentenceType'] == sentence_type]['ManipulationType'],\n",
    "        y=avg_accuracy_drawings[avg_accuracy_drawings['SentenceType'] == sentence_type]['partial_mean'],\n",
    "        name=f'{sentence_type} (partial)',\n",
    "        marker_color=colors[sentence_type][1],  # Lighter shade for partial_mean\n",
    "        marker_pattern_shape=patterns[sentence_type]\n",
    "    ))\n",
    "\n",
    "# Update layout for the custom font and legend\n",
    "fig.update_layout(\n",
    "    font=dict(\n",
    "        family=\"Arial\",\n",
    "        size=15,\n",
    "        color=\"black\"\n",
    "    ),\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=-0.2,\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        font=dict(\n",
    "            family=\"American Typewriter\",\n",
    "            size=16,\n",
    "            color=\"black\"\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(title='Proportion'),\n",
    "    xaxis_title=\"\",\n",
    "    template='plotly_white',\n",
    "    width=800,\n",
    "    height=500,\n",
    ")\n",
    "\n",
    "changes = [-0.3, 0.1, 0.7, 1.1, 1.7, 2.1]\n",
    "# Annotations\n",
    "for i in range(avg_accuracy_drawings.shape[0]):\n",
    "    row = avg_accuracy_drawings.iloc[i]\n",
    "    # Correct mean annotation\n",
    "    fig.add_annotation(\n",
    "        x= changes[i],\n",
    "        y=row['correct_text_position'] + 0.04,\n",
    "        text=f\"{row['correct_mean']:.3f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color='black', size=12),\n",
    "    )\n",
    "    # Partial mean annotation\n",
    "    fig.add_annotation(\n",
    "        x=changes[i] + 0.2,\n",
    "        y=row['partial_text_position'] + 0.04,\n",
    "        text=f\"{row['partial_mean']:.3f}\",\n",
    "        showarrow=False,\n",
    "        font=dict(color='black', size=12),\n",
    "    )\n",
    "\n",
    "# Show the plot\n",
    "fig.write_image('experiments/gardenpath_10_24/analysis/plots/drawings_understood.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.stats import pearsonr, zscore, kendalltau, spearmanr, rankdata\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from math import ceil, fabs\n",
    "\n",
    "\n",
    "df_llm = pd.read_csv('experiments/gardenpath_10_24/results/llm_results/averaged_all.csv')\n",
    "df_humans = pd.read_csv('experiments/gardenpath_10_24/results/human_results/sampled_results.csv')\n",
    "\n",
    "with open('experiments/gardenpath_10_24/analysis/data/families.json', 'r') as f:\n",
    "    families = json.load(f)\n",
    "\n",
    "accuracy_df = df_llm.groupby(['model', 'quest_type']).agg(\n",
    "    avg_accuracy=('avg_correct', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Pivot the data to have quest_type as columns\n",
    "pivoted_accuracy_df = accuracy_df.pivot(index='model', columns='quest_type', values='avg_accuracy').reset_index()\n",
    "\n",
    "# Step 4: Filter models based on accuracy conditions\n",
    "def condition(row):\n",
    "    return (row['simple_question'] - row['GP_question']) >= 0.001\n",
    "\n",
    "filtered_models_accuracy = ['Qwen/Qwen2.5-0.5B', 'Qwen/Qwen2.5-0.5B-Instruct']\n",
    "df_llm = df_llm[~df_llm['model'].isin(filtered_models_accuracy)]\n",
    "\n",
    "df_llm = df_llm[df_llm.quest_type == \"GP_question\"]\n",
    "df_humans = df_humans[df_humans.quest_type == \"GP_question\"]\n",
    "\n",
    "a = df_llm.model.unique()\n",
    "olmo_1 = ['allenai/OLMo-1B-0724-hf_step1218000-tokens2553B',\n",
    "       'allenai/OLMo-1B-0724-hf_step289000-tokens605B',\n",
    "       'allenai/OLMo-1B-0724-hf_step468000-tokens981B',\n",
    "       'allenai/OLMo-1B-0724-hf_step648000-tokens1358B',\n",
    "       'allenai/OLMo-1B-0724-hf_step827000-tokens1733B',]\n",
    "b = a[~np.isin(a, olmo_1)]\n",
    "df_llm = df_llm[df_llm.model.isin(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "model_mapping = {\n",
    "    \"gpt-4\": \"GPT4\", \"gpt-4-turbo\": \"GPT4-Turbo\", \"gpt-4o\": \"GPT4-O\", \"gpt-4o-mini\": \"GPT4-O-Mini\", \"o1-mini\": \"O1-Mini\", \"o1-preview\": \"O1-Preview\",\n",
    "\n",
    "    'meta-llama/Llama-3.2-1B': 'Llama3.2-1B', 'meta-llama/Llama-3.2-1B-Instruct': 'Llama3.2-1B-Inst',\n",
    "    'meta-llama/Llama-3.2-3B': 'Llama3.2-3B', 'meta-llama/Llama-3.2-3B-Instruct': 'Llama3.2-3B-Inst', 'meta-llama/Llama-3.2-11B-Vision': 'Llama3.2-11B-Vis', \n",
    "    'meta-llama/Llama-3.2-11B-Vision-Instruct': 'Llama3.2-11B-Vis-Inst', 'meta-llama/Llama-3.2-90B-Vision': 'Llama3.2-90B-Vis',\n",
    "    'meta-llama/Llama-3.2-90B-Vision-Instruct': 'Llama3.2-90B-Vis-Inst',\n",
    "\n",
    "    'google/gemma-2-2b': 'Gemma-2B', 'google/gemma-2-2b-it': 'Gemma-2B-Inst',  'google/gemma-2-9b': 'Gemma-9B', 'google/gemma-2-9b-it': 'Gemma-9B-Inst', \n",
    "    'google/gemma-2-27b': 'Gemma-27B', 'google/gemma-2-27b-it': 'Gemma-27B-Inst', \n",
    "    \n",
    "    \"Qwen/Qwen2.5-0.5B\": \"Qwen-0.5B\", \"Qwen/Qwen2.5-0.5B-Instruct\": \"Qwen-0.5B-Inst\", \"Qwen/Qwen2.5-1.5B\": \"Qwen-1.5B\", \"Qwen/Qwen2.5-1.5B-Instruct\": \"Qwen-1.5B-Inst\", \n",
    "    \"Qwen/Qwen2.5-3B\": \"Qwen-3B\", \"Qwen/Qwen2.5-3B-Instruct\": \"Qwen-3B-Inst\", \"Qwen/Qwen2.5-7B\": \"Qwen-7B\", \"Qwen/Qwen2.5-7B-Instruct\": \"Qwen-7B-Inst\",\n",
    "    \"Qwen/Qwen2.5-14B\": \"Qwen-14B\", \"Qwen/Qwen2.5-14B-Instruct\": \"Qwen-14B-Inst\", \"Qwen/Qwen2.5-32B\": \"Qwen-32B\", \"Qwen/Qwen2.5-32B-Instruct\": \"Qwen-32B-Inst\",\n",
    "    \"Qwen/Qwen2.5-72B\": \"Qwen-72B\", \"Qwen/Qwen2.5-72B-Instruct\": \"Qwen-72B-Inst\", \n",
    "\n",
    "    'allenai/OLMo-7B-0724-hf_step2000-tokens8B': 'Olmo-7B-Tokens-8B', 'allenai/OLMo-7B-0724-hf_step26500-tokens111B': 'Olmo-7B-Tokens-111B', \n",
    "    'allenai/OLMo-7B-0724-hf_step106500-tokens446B': 'Olmo-7B-Tokens-446B', 'allenai/OLMo-7B-0724-hf_step143000-tokens599B': 'Olmo-7B-Tokens-599B', \n",
    "    'allenai/OLMo-7B-0724-hf_step330000-tokens1384B': 'Olmo-7B-Tokens-1384B', 'allenai/OLMo-7B-0724-hf_step395000-tokens1656B': 'Olmo-7B-Tokens-1656B', 'allenai/OLMo-7B-0724-hf_step458000-tokens1920B': 'Olmo-7B-Tokens-1920B',\n",
    "    'allenai/OLMo-7B-0724-hf_step519000-tokens2176B': 'Olmo-7B-Tokens-2176B', 'allenai/OLMo-7B-0724-hf_step582000-tokens2441B': 'Olmo-7B-Tokens-2441B',\n",
    "    'allenai/OLMo-7B-0724-hf_step647650-tokens2716B': 'Olmo-7B-Tokens-2716B', 'allenai/OLMo-7B-0724-hf_step650650-tokens2729B': 'Olmo-7B-Tokens-2729B',\n",
    "    \n",
    "    'allenai/OLMo-1B-0724-hf_step20000-tokens41B': 'Olmo-1B-Tokens-41B', 'allenai/OLMo-1B-0724-hf_step289000-tokens605B': 'Olmo-1B-Tokens-605B',\n",
    "    'allenai/OLMo-1B-0724-hf_step379000-tokens794B': 'Olmo-1B-Tokens-794B', 'allenai/OLMo-1B-0724-hf_step468000-tokens981B': 'Olmo-1B-Tokens-981B',\n",
    "    'allenai/OLMo-1B-0724-hf_step558000-tokens1169B': 'Olmo-1B-Tokens-1169B', 'allenai/OLMo-1B-0724-hf_step648000-tokens1358B': 'Olmo-1B-Tokens-1358B',\n",
    "    'allenai/OLMo-1B-0724-hf_step738000-tokens1547B': 'Olmo-1B-Tokens-1547B', 'allenai/OLMo-1B-0724-hf_step827000-tokens1733B': 'Olmo-1B-Tokens-1733B',\n",
    "    'allenai/OLMo-1B-0724-hf_step917000-tokens1922B': 'Olmo-1B-Tokens-1922B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1038000-tokens2176B': 'Olmo-1B-Tokens-2176B', 'allenai/OLMo-1B-0724-hf_step1128000-tokens2364B': 'Olmo-1B-Tokens-2346B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1218000-tokens2553B': 'Olmo-1B-Tokens-2553B', 'allenai/OLMo-1B-0724-hf_step1308000-tokens2742B': 'Olmo-1B-Tokens-2742B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1399000-tokens2932B': 'Olmo-1B-Tokens-2932B', 'allenai/OLMo-1B-0724-hf_step1454000-tokens3048B': 'Olmo-1B-Tokens-3048B',}\n",
    "\n",
    "\n",
    "def extract_step(model_name):\n",
    "    if 'allenai' in model_name:\n",
    "        step_num = model_name.split('tokens')[-1].replace('B', '')\n",
    "    elif 'Eleuther' in model_name:\n",
    "        step_num = model_name.split('step')[-1]\n",
    "    else:\n",
    "        step_num = model_name.split('ckpt_')[-1]\n",
    "    return step_num\n",
    "\n",
    "\n",
    "def convert_to_num(string):\n",
    "    try:\n",
    "        return float(string)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_model_parameters(model_name, family_name = None):\n",
    "\n",
    "    if family_name in ['Pythia-1.4b', 'Pythia-1b', 'Pythia-2.8b', 'Pythia-6.9b', 'OLMo-1b', 'OLMo-7b', 'Pythia-12b', \"K2\", 'Amber']:\n",
    "        return int(extract_step(model_name))\n",
    "    \n",
    "    model_name = model_name.lower()\n",
    "    parts = model_name.split('-')\n",
    "    for part in parts:\n",
    "        if 'b' in part:\n",
    "            num_params_new = convert_to_num(part.replace('b', ''))\n",
    "            if num_params_new is not None:\n",
    "                return num_params_new\n",
    "    return -1\n",
    "\n",
    "\n",
    "def is_instruction_tuned(model_name):\n",
    "    return 'inst' in model_name.lower() or 'gpt' in model_name.lower() or 'it' in model_name.lower() or 'chat' in model_name.lower() or 'vicuna' in model_name.lower() or 'iml' in model_name.lower() or 'o1-' in model_name.lower()\n",
    "\n",
    "\n",
    "def rank_correlation(llm_df, human_df, families):\n",
    "\n",
    "    model_to_family = {}\n",
    "    basic_keys = [\"OLMo-7b\", \"OLMo-1b\", \"Llama-3.2\", \"Qwen-2.5\", \"Gemma-2\", \"GPT\"]\n",
    "    for family, models in families.items():\n",
    "        if family not in basic_keys:\n",
    "            continue\n",
    "        for model in models:\n",
    "            model_to_family[model] = family\n",
    "\n",
    "    llm_df['Family'] = llm_df['model'].map(model_to_family)\n",
    "    human_df['model'] = 'Human'\n",
    "    human_df['Family'] = 'Human'\n",
    "\n",
    "    human_item_perf = human_df.groupby(['sent_type', 'quest_type', 'set_id'])['correct'].mean().reset_index()\n",
    "    human_item_perf = human_item_perf.rename(columns={'correct': 'human_accuracy'})\n",
    "\n",
    "    llm_item_perf = llm_df.copy()\n",
    "    llm_item_perf = llm_item_perf.rename(columns={'avg_correct': 'llm_performance'})\n",
    "\n",
    "    # Group the dataframe by ('sentence', 'question')\n",
    "    grouped = df_humans.groupby(['sentence', 'question'])\n",
    "\n",
    "    # Initialize empty lists to collect group data\n",
    "    group1_list = []\n",
    "    group2_list = []\n",
    "\n",
    "    for name, group in grouped:\n",
    "        # Shuffle the group data\n",
    "        shuffled_group = group.sample(frac=1, random_state=1)  # Seed for reproducibility if needed\n",
    "        # Split the group into two halves\n",
    "        group1 = shuffled_group.iloc[:5]\n",
    "        group2 = shuffled_group.iloc[5:]\n",
    "        group1_list.append(group1)\n",
    "        group2_list.append(group2)\n",
    "\n",
    "    # Concatenate lists into DataFrames\n",
    "    df_group1 = pd.concat(group1_list).reset_index(drop=True)\n",
    "    df_group2 = pd.concat(group2_list).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    half_1_item_perf = df_group1.groupby(['sent_type', 'quest_type', 'set_id'])['correct'].mean().reset_index()\n",
    "    half_1_item_perf = half_1_item_perf.rename(columns={'correct': 'half_1_accuracy'})\n",
    "\n",
    "    half_2_item_perf = df_group2.groupby(['sent_type', 'quest_type', 'set_id'])['correct'].mean().reset_index()\n",
    "    half_2_item_perf = half_2_item_perf.rename(columns={'correct': 'half_2_accuracy'})\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        llm_item_perf,\n",
    "        human_item_perf,\n",
    "        on=['sent_type', 'quest_type', 'set_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        half_1_item_perf,\n",
    "        on=['sent_type', 'quest_type', 'set_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        half_2_item_perf,\n",
    "        on=['sent_type', 'quest_type', 'set_id'],\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "    conditions = merged_df[['sent_type', 'quest_type']].drop_duplicates()\n",
    "    similarity_results = defaultdict(lambda: list())\n",
    "\n",
    "    tasks = ['Global']\n",
    "\n",
    "    sentence_mappings = {'GP_prob_GP_question': 'GP-Plaus.',\n",
    "                         'nonGP_prob_GP_question': 'nonGP-Plaus.',\n",
    "                         'GP_improb_GP_question': 'GP-Implaus.',\n",
    "                         'nonGP_improb_GP_question': 'nonGP-Implaus.',\n",
    "                         'GP_reflexive_GP_question': 'GP-Reflexive.',\n",
    "                         'nonGP_reflexive_GP_question': 'nonGP-Reflexive.',\n",
    "                         'Global': 'Global'}\n",
    "    \n",
    "    variance_std = defaultdict(lambda: defaultdict(lambda: dict()))\n",
    "    \n",
    "    for model in merged_df['model'].unique():\n",
    "        if model == 'Human':\n",
    "            continue  # Skip human vs. human comparison\n",
    "        model_data = merged_df[merged_df['model'] == model]\n",
    "        model_data = model_data.fillna(0)\n",
    "    \n",
    "        # Ensure there are enough items to compute correlation\n",
    "        if len(model_data) < 2:\n",
    "            continue  # Not enough data to compute correlation\n",
    "    \n",
    "        # Get the per-item performances\n",
    "        human_perf = model_data['human_accuracy']\n",
    "        llm_perf = model_data['llm_performance']\n",
    "        human_ranks = rankdata([1 - x for x in human_perf], method='average')\n",
    "        LLM_ranks = rankdata([1 - x for x in llm_perf], method='average')\n",
    "        # Compute Spearman rank correlation\n",
    "        corr_coef, p_value = kendalltau(human_ranks, LLM_ranks)\n",
    "        if np.isnan(corr_coef):\n",
    "            corr_coef = 0.0\n",
    "        similarity_results[model].append(corr_coef)\n",
    "            \n",
    "    h1_perf = model_data['half_1_accuracy']\n",
    "    h2_perf = model_data['half_2_accuracy']\n",
    "    human_ranks = rankdata([1 - x for x in h1_perf], method='average')\n",
    "    LLM_ranks = rankdata([1 - x for x in h2_perf], method='average')\n",
    "    # Compute Spearman rank correlation\n",
    "    corr_coef, p_value = kendalltau(human_ranks, LLM_ranks)\n",
    "    if np.isnan(corr_coef):\n",
    "        corr_coef = 0.0\n",
    "    similarity_results['Half_split'].append(corr_coef)\n",
    "        \n",
    "\n",
    "    for idx, condition_row in conditions.iterrows():\n",
    "        sent_type = condition_row['sent_type']\n",
    "        quest_type = condition_row['quest_type']\n",
    "        condition_name = f\"{sent_type}_{quest_type}\"\n",
    "\n",
    "        tasks.append(sentence_mappings[condition_name])\n",
    "    \n",
    "        # Subset data for the current condition\n",
    "        condition_data = merged_df[\n",
    "            (merged_df['sent_type'] == sent_type) &\n",
    "            (merged_df['quest_type'] == quest_type)\n",
    "        ]\n",
    "    \n",
    "        # Get unique models\n",
    "        models = condition_data['model'].unique()\n",
    "\n",
    "        h1_perf = condition_data['half_1_accuracy']\n",
    "        h2_perf = condition_data['half_2_accuracy']\n",
    "        human_ranks = rankdata([1 - x for x in h1_perf], method='average')\n",
    "        LLM_ranks = rankdata([1 - x for x in h2_perf], method='average')\n",
    "        # Compute Spearman rank correlation\n",
    "        corr_coef, p_value = kendalltau(human_ranks, LLM_ranks)\n",
    "        if np.isnan(corr_coef):\n",
    "            corr_coef = 0.0\n",
    "        similarity_results['Half_split'].append(corr_coef)\n",
    "    \n",
    "        # For each model, compute Spearman rank correlation with human data\n",
    "        for model in models:\n",
    "            if model == 'Human':\n",
    "                continue  # Skip human vs. human comparison\n",
    "            model_data = condition_data[condition_data['model'] == model]\n",
    "            model_data = model_data.fillna(0)\n",
    "        \n",
    "            # Ensure there are enough items to compute correlation\n",
    "            if len(model_data) < 2:\n",
    "                continue  # Not enough data to compute correlation\n",
    "        \n",
    "            # Get the per-item performances\n",
    "            human_perf = model_data['human_accuracy']\n",
    "            llm_perf = model_data['llm_performance']\n",
    "\n",
    "            variance_std[model][condition_name]['std'] = np.std(llm_perf)\n",
    "            variance_std[model][condition_name]['variance'] = np.var(llm_perf)\n",
    "            variance_std[model][condition_name]['mean'] = np.mean(llm_perf)\n",
    "\n",
    "            variance_std['humans'][condition_name]['std'] = np.std(human_perf)\n",
    "            variance_std['humans'][condition_name]['variance'] = np.var(human_perf)\n",
    "            variance_std['humans'][condition_name]['mean'] = np.mean(human_perf)\n",
    "\n",
    "            human_ranks = rankdata([1 - x for x in human_perf], method='average')\n",
    "            LLM_ranks = rankdata([1 - x for x in llm_perf], method='average')\n",
    "            # Compute Spearman rank correlation\n",
    "            corr_coef, p_value = kendalltau(human_ranks, LLM_ranks)\n",
    "            if np.isnan(corr_coef):\n",
    "                corr_coef = 0.0\n",
    "            similarity_results[model].append(corr_coef)\n",
    "\n",
    "    weights = [45 / 228, 45 / 228, 45 / 228, 45 / 228, 24 / 228, 24 / 228]\n",
    "    for model in similarity_results:\n",
    "        # we insert the average of the correlations as the second element of the list\n",
    "        similarity_results[model].insert(1, np.average(similarity_results[model][1:], weights=weights))\n",
    "    \n",
    "    tasks.insert(1, 'Averaged')\n",
    "        \n",
    "    similarity_results['Human'] = [1.0] * len(similarity_results['o1-preview'])\n",
    "\n",
    "    similarity_df = pd.DataFrame.from_dict(similarity_results, orient='index', columns=tasks)\n",
    "\n",
    "    return merged_df, similarity_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5_/7jnqp3zj071c_6wswzvn61j40000gn/T/ipykernel_20768/2602187178.py:165: FutureWarning:\n",
      "\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "\n",
      "/var/folders/5_/7jnqp3zj071c_6wswzvn61j40000gn/T/ipykernel_20768/2602187178.py:224: FutureWarning:\n",
      "\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = df_humans.sentence.to_list()\n",
    "set_ids = df_humans.set_id.to_list()\n",
    "\n",
    "set_mapping = dict(zip(sentences, set_ids))\n",
    "df_llm['set_id'] = df_llm['sentence'].map(set_mapping)\n",
    "merged_df, similarity_df = rank_correlation(df_llm, df_humans, families)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_distance_graph(distances_df, families, dist_name='L2 distance'):\n",
    "\n",
    "    model_to_family = {}\n",
    "    for family, models in families.items():\n",
    "        for model in models:\n",
    "            model_to_family[model] = family\n",
    "\n",
    "    distances_df['Family'] = distances_df.index.map(model_to_family)\n",
    "    basic_keys = [\"GPT\", \"Llama-3.2\", \"Gemma-2\", \"Qwen-2.5\", \"OLMo-7b\", \"OLMo-1b\"]\n",
    "    distances_df = distances_df[distances_df['Family'].isin(basic_keys)]\n",
    "\n",
    "    # we want the families to appear in the same order as in basic keys\n",
    "    distances_df['Family'] = pd.Categorical(distances_df['Family'], categories=basic_keys, ordered=True)\n",
    "\n",
    "    family_list = sorted(distances_df['Family'].dropna().unique())\n",
    "    num_families = len(family_list)\n",
    "    colors = px.colors.qualitative.Plotly\n",
    "    if num_families > len(colors):\n",
    "        colors = colors * ((num_families // len(colors)) + 1)\n",
    "    family_colors = dict(zip(family_list, colors[:num_families]))\n",
    "\n",
    "    model_names = distances_df.index\n",
    "    instructions_tuned = [is_instruction_tuned(name) for name in model_names]\n",
    "    num_params = [get_model_parameters(name, model_to_family[name]) for name in model_names]\n",
    "\n",
    "    distances_df['instruction_tuned'] = instructions_tuned\n",
    "    distances_df['model_name'] = model_names\n",
    "    distances_df['num_params'] = num_params\n",
    "\n",
    "    families = distances_df['Family'].unique()\n",
    "    num_families = len(families)\n",
    "\n",
    "    # Set up the subplot grid\n",
    "    cols = 2\n",
    "    rows = ceil(num_families / cols)\n",
    "    fig = make_subplots(\n",
    "        rows=rows, \n",
    "        cols=cols, \n",
    "        subplot_titles=basic_keys, \n",
    "        shared_xaxes=False, \n",
    "        shared_yaxes=True, \n",
    "        horizontal_spacing=0.05  # Reduce distance between columns\n",
    "    )\n",
    "\n",
    "    # Update layout template\n",
    "    fig.update_layout(template=\"plotly_white\")\n",
    "\n",
    "    # Define colors and patterns for instruction-tuned and non-instruction-tuned models\n",
    "    colors = {True: 'lightcoral', False: 'lightcyan'}\n",
    "    patterns = {True: \"/\", False: \"\\\\\"}\n",
    "\n",
    "    # Loop through each family to create subplots\n",
    "    for i, family in enumerate(basic_keys):\n",
    "        family_df = distances_df[distances_df['Family'] == family]\n",
    "        if family_df.empty:\n",
    "            continue\n",
    "\n",
    "        row = (i // cols) + 1\n",
    "        col = (i % cols) + 1\n",
    "\n",
    "        if family == 'GPT':\n",
    "            x_var = 'nicknames'\n",
    "            x_categories = sorted(family_df[x_var].unique())\n",
    "            family_df[x_var] = pd.Categorical(family_df[x_var], categories=x_categories, ordered=True)\n",
    "        else:\n",
    "            x_var = 'num_params_str'\n",
    "            num_params_list = sorted(family_df['num_params'].unique())\n",
    "            x_categories = [str(n) for n in num_params_list]\n",
    "            family_df['num_params_str'] = family_df['num_params'].astype(str)\n",
    "            family_df['num_params_str'] = pd.Categorical(family_df['num_params_str'], categories=x_categories, ordered=True)\n",
    "\n",
    "        # Loop through instruction_tuned values\n",
    "        for instruction_tuned_value in [True, False]:\n",
    "            df_filtered = family_df[family_df['instruction_tuned'] == instruction_tuned_value]\n",
    "            if df_filtered.empty:\n",
    "                continue\n",
    "\n",
    "            df_filtered = df_filtered.sort_values(x_var)\n",
    "\n",
    "            trace_bar = go.Bar(\n",
    "                x=df_filtered[x_var],\n",
    "                y=df_filtered['Global'],\n",
    "                name='Instruction Tuned' if instruction_tuned_value else 'Not Instruction Tuned',\n",
    "                marker_color=colors[instruction_tuned_value],\n",
    "                marker_pattern_shape=patterns[instruction_tuned_value],\n",
    "                showlegend=(family == \"Qwen-2.5\"),  # Show legend only once\n",
    "            )\n",
    "            fig.add_trace(trace_bar, row=row, col=col)\n",
    "\n",
    "        # Update axes titles for each subplot\n",
    "        if family == \"GPT\":\n",
    "            x_axis_title = 'Model Name'\n",
    "        elif \"OLM\" in family:\n",
    "            x_axis_title = 'Number of Tokens (Billions)'\n",
    "        else:\n",
    "            x_axis_title = 'Number of Parameters (Billions)'\n",
    "\n",
    "        fig.update_xaxes(title_text=x_axis_title, row=row, col=col)\n",
    "        show_y_axis_title = (col == 1)\n",
    "        fig.update_yaxes(\n",
    "            title_text=\"Spearman\" if show_y_axis_title else None, \n",
    "            showticklabels=show_y_axis_title, \n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "    # Update the layout of the figure\n",
    "    fig.update_layout(\n",
    "        barmode='group',\n",
    "        title=dict(\n",
    "            text=f\"{dist_name} by Model Family\",\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        legend_title_text='Model Type',\n",
    "        height=rows * 300,  # Adjust height for smaller subplots\n",
    "        width=800,  # Adjust width\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "GPT4",
          "GPT4-O",
          "GPT4-O-M",
          "GPT4-T",
          "O1-M",
          "O1-Prev."
         ],
         "xaxis": "x",
         "y": [
          0.5847773322801504,
          0.5089032916762277,
          0.5321132185254631,
          0.5474149878869874,
          0.5682748599311778,
          0.43072048289012665
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "1.0",
          "3.0",
          "11.0",
          "90.0"
         ],
         "xaxis": "x2",
         "y": [
          0.2797122007596094,
          0.4383403867205727,
          0.4943937174270541,
          0.5868933440737744
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "1.0",
          "3.0",
          "11.0",
          "90.0"
         ],
         "xaxis": "x2",
         "y": [
          0.09876432395764147,
          0.39178695397766383,
          0.4916141390374985,
          0.5915230826436556
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "2.0",
          "9.0",
          "27.0"
         ],
         "xaxis": "x3",
         "y": [
          0.3801772403998616,
          0.5611906619579893,
          0.5665049674689551
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "2.0",
          "9.0",
          "27.0"
         ],
         "xaxis": "x3",
         "y": [
          0.3586747427170307,
          0.5574297688271519,
          0.5762342344813386
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": true,
         "type": "bar",
         "x": [
          "1.5",
          "3.0",
          "7.0",
          "14.0",
          "32.0",
          "72.0"
         ],
         "xaxis": "x4",
         "y": [
          0.41662364220227593,
          0.47868626845290047,
          0.5178360705960109,
          0.5223343926937944,
          0.5443132154702758,
          0.5872038165324873
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": true,
         "type": "bar",
         "x": [
          "1.5",
          "3.0",
          "7.0",
          "14.0",
          "32.0",
          "72.0"
         ],
         "xaxis": "x4",
         "y": [
          0.4530241051732544,
          0.43037698784190787,
          0.4894884168331121,
          0.4975007543727221,
          0.559964283763151,
          0.5894791189855919
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "8.0",
          "111.0",
          "446.0",
          "599.0",
          "1384.0",
          "1656.0",
          "1920.0",
          "2176.0",
          "2441.0",
          "2716.0",
          "2729.0"
         ],
         "xaxis": "x5",
         "y": [
          -0.024609322443087816,
          -0.010465093929286512,
          0.2917962518251841,
          0.3580206743464503,
          0.4375717399182923,
          0.471501536642151,
          0.4460746287358376,
          0.4693758144377646,
          0.5046955064491065,
          0.5527695316867665,
          0.5303676899943875
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "41.0",
          "794.0",
          "1169.0",
          "1547.0",
          "1922.0",
          "2176.0",
          "2364.0",
          "2742.0",
          "2932.0",
          "3048.0"
         ],
         "xaxis": "x6",
         "y": [
          0.044231373560500026,
          0.20079898976818497,
          0.26824979048428943,
          0.12460002459556754,
          0.06532507851171816,
          0.22181093617308056,
          0.17651670151038737,
          0.21870411141282362,
          0.19597523553515447,
          0.23783561125230054
         ],
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "GPT",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Llama-3.2",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Gemma-2",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Qwen-2.5",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OLMo-7b",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OLMo-1b",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "font": {
         "color": "black"
        },
        "height": 900,
        "legend": {
         "font": {
          "color": "black",
          "family": "Arial",
          "size": 13
         },
         "orientation": "h",
         "title": {
          "text": "Model Type"
         },
         "x": 0.5,
         "xanchor": "center",
         "y": -0.15,
         "yanchor": "bottom"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Kendall Tau Rank Correlation (item level) by Model Family",
         "x": 0.5,
         "xanchor": "center"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.475
         ],
         "title": {
          "text": "Model Name"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.525,
          1
         ],
         "title": {
          "text": "Number of Parameters (Billions)"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.475
         ],
         "title": {
          "text": "Number of Parameters (Billions)"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.525,
          1
         ],
         "title": {
          "text": "Number of Parameters (Billions)"
         }
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.475
         ],
         "title": {
          "text": "Number of Tokens (Billions)"
         }
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.525,
          1
         ],
         "title": {
          "text": "Number of Tokens (Billions)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7777777777777778,
          1
         ],
         "showticklabels": true,
         "title": {
          "text": "Spearman"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7777777777777778,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ],
         "showticklabels": true,
         "title": {
          "text": "Spearman"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ],
         "matches": "y3",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.22222222222222224
         ],
         "showticklabels": true,
         "title": {
          "text": "Spearman"
         }
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.22222222222222224
         ],
         "matches": "y5",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_mapping_short = {\n",
    "    \"gpt-4\": \"GPT4\", \"gpt-4-turbo\": \"GPT4-T\", \"gpt-4o\": \"GPT4-O\", \"gpt-4o-mini\": \"GPT4-O-M\", \"o1-mini\": \"O1-M\", \"o1-preview\": \"O1-Prev.\",\n",
    "\n",
    "    'meta-llama/Llama-3.2-1B': 'Llama3.2-1B', 'meta-llama/Llama-3.2-1B-Instruct': 'Llama3.2-1B-Inst',\n",
    "    'meta-llama/Llama-3.2-3B': 'Llama3.2-3B', 'meta-llama/Llama-3.2-3B-Instruct': 'Llama3.2-3B-Inst', 'meta-llama/Llama-3.2-11B-Vision': 'Llama3.2-11B-Vis', \n",
    "    'meta-llama/Llama-3.2-11B-Vision-Instruct': 'Llama3.2-11B-Vis-Inst', 'meta-llama/Llama-3.2-90B-Vision': 'Llama3.2-90B-Vis',\n",
    "    'meta-llama/Llama-3.2-90B-Vision-Instruct': 'Llama3.2-90B-Vis-Inst',\n",
    "\n",
    "    'google/gemma-2-2b': 'Gemma-2B', 'google/gemma-2-2b-it': 'Gemma-2B-Inst',  'google/gemma-2-9b': 'Gemma-9B', 'google/gemma-2-9b-it': 'Gemma-9B-Inst', \n",
    "    'google/gemma-2-27b': 'Gemma-27B', 'google/gemma-2-27b-it': 'Gemma-27B-Inst', \n",
    "    \n",
    "    \"Qwen/Qwen2.5-0.5B\": \"Qwen-0.5B\", \"Qwen/Qwen2.5-0.5B-Instruct\": \"Qwen-0.5B-Inst\", \"Qwen/Qwen2.5-1.5B\": \"Qwen-1.5B\", \"Qwen/Qwen2.5-1.5B-Instruct\": \"Qwen-1.5B-Inst\", \n",
    "    \"Qwen/Qwen2.5-3B\": \"Qwen-3B\", \"Qwen/Qwen2.5-3B-Instruct\": \"Qwen-3B-Inst\", \"Qwen/Qwen2.5-7B\": \"Qwen-7B\", \"Qwen/Qwen2.5-7B-Instruct\": \"Qwen-7B-Inst\",\n",
    "    \"Qwen/Qwen2.5-14B\": \"Qwen-14B\", \"Qwen/Qwen2.5-14B-Instruct\": \"Qwen-14B-Inst\", \"Qwen/Qwen2.5-32B\": \"Qwen-32B\", \"Qwen/Qwen2.5-32B-Instruct\": \"Qwen-32B-Inst\",\n",
    "    \"Qwen/Qwen2.5-72B\": \"Qwen-72B\", \"Qwen/Qwen2.5-72B-Instruct\": \"Qwen-72B-Inst\", \n",
    "    \n",
    "    'allenai/OLMo-7B-0724-hf_step26500-tokens111B': 'Olmo-7B-Tokens-111B', \n",
    "    'allenai/OLMo-7B-0724-hf_step106500-tokens446B': 'Olmo-7B-Tokens-446B', \n",
    "    'allenai/OLMo-7B-0724-hf_step330000-tokens1384B': 'Olmo-7B-Tokens-1384B', \n",
    "    'allenai/OLMo-7B-0724-hf_step519000-tokens2176B': 'Olmo-7B-Tokens-2176B',\n",
    "    'allenai/OLMo-7B-0724-hf_step647650-tokens2716B': 'Olmo-7B-Tokens-2716B', 'allenai/OLMo-7B-0724-hf_step650650-tokens2729B': 'Olmo-7B-Tokens-2729B',\n",
    "    \n",
    "    'allenai/OLMo-1B-0724-hf_step20000-tokens41B': 'Olmo-1B-Tokens-41B', \n",
    "    'allenai/OLMo-1B-0724-hf_step379000-tokens794B': 'Olmo-1B-Tokens-794B',\n",
    "    'allenai/OLMo-1B-0724-hf_step558000-tokens1169B': 'Olmo-1B-Tokens-1169B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1038000-tokens2176B': 'Olmo-1B-Tokens-2176B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1218000-tokens2553B': 'Olmo-1B-Tokens-2553B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1454000-tokens3048B': 'Olmo-1B-Tokens-3048B'}\n",
    "\n",
    "similarity_df['nicknames'] = similarity_df.index.map(model_mapping_short)\n",
    "fig = output_distance_graph(similarity_df, families, dist_name='Kendall Tau Rank Correlation (item level)')\n",
    "fig.update_layout(\n",
    "    font=dict(color='black'),\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=-0.15,\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        font=dict(\n",
    "            family=\"Arial\",\n",
    "            color=\"black\",\n",
    "            size=13\n",
    "        )\n",
    "    )\n",
    ")\n",
    "fig.write_image('experiments/gardenpath_10_24/analysis/plots/per_family_item_tau.pdf')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelamouyal/miniconda/envs/neuro_nlp_new/lib/python3.11/site-packages/scipy/stats/_stats_py.py:4921: ConstantInputWarning:\n",
      "\n",
      "An input array is constant; the correlation coefficient is not defined.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "GPT4",
          "GPT4-O",
          "GPT4-O-M",
          "GPT4-T",
          "O1-M",
          "O1-Prev."
         ],
         "xaxis": "x",
         "y": [
          0.942857142857143,
          0.7714285714285715,
          0.942857142857143,
          0.942857142857143,
          1,
          0.7714285714285715
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "1.0",
          "3.0",
          "11.0",
          "90.0"
         ],
         "xaxis": "x2",
         "y": [
          0.8857142857142858,
          0.8857142857142858,
          0.942857142857143,
          0.8857142857142858
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "1.0",
          "3.0",
          "11.0",
          "90.0"
         ],
         "xaxis": "x2",
         "y": [
          0.7142857142857143,
          0.8857142857142858,
          0.942857142857143,
          0.8857142857142858
         ],
         "yaxis": "y2"
        },
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "2.0",
          "9.0",
          "27.0"
         ],
         "xaxis": "x3",
         "y": [
          0.6571428571428573,
          0.8857142857142858,
          0.942857142857143
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "2.0",
          "9.0",
          "27.0"
         ],
         "xaxis": "x3",
         "y": [
          0.8857142857142858,
          0.8857142857142858,
          0.942857142857143
         ],
         "yaxis": "y3"
        },
        {
         "marker": {
          "color": "lightcoral",
          "pattern": {
           "shape": "/"
          }
         },
         "name": "Instruction Tuned",
         "showlegend": true,
         "type": "bar",
         "x": [
          "1.5",
          "3.0",
          "7.0",
          "14.0",
          "32.0",
          "72.0"
         ],
         "xaxis": "x4",
         "y": [
          0.8857142857142858,
          0.8857142857142858,
          0.942857142857143,
          0.8857142857142858,
          0.942857142857143,
          0.942857142857143
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": true,
         "type": "bar",
         "x": [
          "1.5",
          "3.0",
          "7.0",
          "14.0",
          "32.0",
          "72.0"
         ],
         "xaxis": "x4",
         "y": [
          0.8857142857142858,
          0.942857142857143,
          0.942857142857143,
          0.7714285714285715,
          0.8285714285714287,
          0.942857142857143
         ],
         "yaxis": "y4"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "8.0",
          "111.0",
          "446.0",
          "599.0",
          "1384.0",
          "1656.0",
          "1920.0",
          "2176.0",
          "2441.0",
          "2716.0",
          "2729.0"
         ],
         "xaxis": "x5",
         "y": [
          0.08571428571428573,
          0.5428571428571429,
          0.7714285714285715,
          0.8857142857142858,
          0.8857142857142858,
          0.8857142857142858,
          0.942857142857143,
          0.8857142857142858,
          0.8857142857142858,
          0.8857142857142858,
          0.8857142857142858
         ],
         "yaxis": "y5"
        },
        {
         "marker": {
          "color": "lightcyan",
          "pattern": {
           "shape": "\\"
          }
         },
         "name": "Not Instruction Tuned",
         "showlegend": false,
         "type": "bar",
         "x": [
          "41.0",
          "794.0",
          "1169.0",
          "1547.0",
          "1922.0",
          "2176.0",
          "2364.0",
          "2742.0",
          "2932.0",
          "3048.0"
         ],
         "xaxis": "x6",
         "y": [
          0.6571428571428573,
          0.8857142857142858,
          0.6571428571428573,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.6571428571428573,
          0.7714285714285715
         ],
         "yaxis": "y6"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "GPT",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Llama-3.2",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Gemma-2",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Qwen-2.5",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.6111111111111112,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OLMo-7b",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "OLMo-1b",
          "x": 0.7625,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.22222222222222224,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "barmode": "group",
        "font": {
         "color": "black"
        },
        "height": 900,
        "legend": {
         "font": {
          "color": "black",
          "family": "Arial",
          "size": 13
         },
         "orientation": "h",
         "title": {
          "text": "Model Type"
         },
         "x": 0.5,
         "xanchor": "center",
         "y": -0.15,
         "yanchor": "bottom"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "#C8D4E3"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "#EBF0F8",
            "linecolor": "#EBF0F8",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "#DFE8F3",
            "gridwidth": 2,
            "linecolor": "#EBF0F8",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "#EBF0F8"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "#DFE8F3",
            "linecolor": "#A2B1C6",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "#EBF0F8",
           "linecolor": "#EBF0F8",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "#EBF0F8",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Spearman correlation (by category) by Model Family",
         "x": 0.5,
         "xanchor": "center"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.475
         ],
         "title": {
          "text": "Model Name"
         }
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.525,
          1
         ],
         "title": {
          "text": "Number of Parameters (Billions)"
         }
        },
        "xaxis3": {
         "anchor": "y3",
         "domain": [
          0,
          0.475
         ],
         "title": {
          "text": "Number of Parameters (Billions)"
         }
        },
        "xaxis4": {
         "anchor": "y4",
         "domain": [
          0.525,
          1
         ],
         "title": {
          "text": "Number of Parameters (Billions)"
         }
        },
        "xaxis5": {
         "anchor": "y5",
         "domain": [
          0,
          0.475
         ],
         "title": {
          "text": "Number of Tokens (Billions)"
         }
        },
        "xaxis6": {
         "anchor": "y6",
         "domain": [
          0.525,
          1
         ],
         "title": {
          "text": "Number of Tokens (Billions)"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0.7777777777777778,
          1
         ],
         "showticklabels": true,
         "title": {
          "text": "Spearman"
         }
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0.7777777777777778,
          1
         ],
         "matches": "y",
         "showticklabels": false
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ],
         "showticklabels": true,
         "title": {
          "text": "Spearman"
         }
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.3888888888888889,
          0.6111111111111112
         ],
         "matches": "y3",
         "showticklabels": false
        },
        "yaxis5": {
         "anchor": "x5",
         "domain": [
          0,
          0.22222222222222224
         ],
         "showticklabels": true,
         "title": {
          "text": "Spearman"
         }
        },
        "yaxis6": {
         "anchor": "x6",
         "domain": [
          0,
          0.22222222222222224
         ],
         "matches": "y5",
         "showticklabels": false
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_data_distance(llm_df, human_df, families):\n",
    "\n",
    "    human_performance = human_df.groupby(['sent_type', 'quest_type'])['correct'].mean().reset_index()\n",
    "    human_performance['model'] = 'Human'\n",
    "\n",
    "    llm_performance = llm_df.groupby(['model', 'sent_type', 'quest_type'])['avg_correct'].mean().reset_index()\n",
    "\n",
    "    human_performance['condition'] = human_performance['sent_type'] + '_' + human_performance['quest_type']\n",
    "    llm_performance['condition'] = llm_performance['sent_type'] + '_' + llm_performance['quest_type']\n",
    "\n",
    "    human_pivot = human_performance.pivot(index='model', columns='condition', values='correct')\n",
    "    llm_pivot = llm_performance.pivot(index='model', columns='condition', values='avg_correct')\n",
    "\n",
    "    performance_df = pd.concat([human_pivot, llm_pivot])\n",
    "    performance_df = performance_df.fillna(0)\n",
    "    return performance_df\n",
    "\n",
    "\n",
    "performance_df = prepare_data_distance(df_llm, df_humans, families)\n",
    "\n",
    "def spearman_distance(performance_df_norm):\n",
    "\n",
    "    performance_ranks = performance_df_norm.rank(axis=1, method='average', ascending=False)\n",
    "    human_ranks = performance_ranks.loc['Human']\n",
    "\n",
    "    distances = {}\n",
    "    for model in performance_ranks.index:\n",
    "        if model != 'Human':\n",
    "            model_ranks = performance_ranks.loc[model]\n",
    "            corr_coef, _ = spearmanr(human_ranks, model_ranks)\n",
    "            distance = corr_coef\n",
    "            distances[model] = distance\n",
    "\n",
    "    distances_df = pd.DataFrame.from_dict(distances, orient='index', columns=['Global'])\n",
    "    distances_df = distances_df.sort_values('Global')\n",
    "    return distances_df\n",
    "\n",
    "spearman_distances_df = spearman_distance(performance_df)\n",
    "spearman_distances_df['nicknames'] = spearman_distances_df.index.map(model_mapping_short)\n",
    "fig = output_distance_graph(spearman_distances_df, families, \"Spearman correlation (by category)\")\n",
    "fig.update_layout(\n",
    "    font=dict(color='black'),\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        yanchor='bottom',\n",
    "        y=-0.15,\n",
    "        xanchor='center',\n",
    "        x=0.5,\n",
    "        font=dict(\n",
    "            family=\"Arial\",\n",
    "            color=\"black\",\n",
    "            size=13\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.write_image('experiments/gardenpath_10_24/analysis/plots/per_category_cat_spearman.pdf')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mapping_short = {\n",
    "    \"gpt-4\": \"GPT4\", \"gpt-4-turbo\": \"GPT4-T\", \"gpt-4o\": \"GPT4-O\", \"gpt-4o-mini\": \"GPT4-O-M\", \"o1-mini\": \"O1-Mini\", \"o1-preview\": \"O1-Prev.\",\n",
    "\n",
    "    'meta-llama/Llama-3.2-1B': 'Llama3.2-1B', 'meta-llama/Llama-3.2-1B-Instruct': 'Llama3.2-1B-Inst',\n",
    "    'meta-llama/Llama-3.2-3B': 'Llama3.2-3B', 'meta-llama/Llama-3.2-3B-Instruct': 'Llama3.2-3B-Inst', 'meta-llama/Llama-3.2-11B-Vision': 'Llama3.2-11B-Vis', \n",
    "    'meta-llama/Llama-3.2-11B-Vision-Instruct': 'Llama3.2-11B-Vis-Inst', 'meta-llama/Llama-3.2-90B-Vision': 'Llama3.2-90B-Vis',\n",
    "    'meta-llama/Llama-3.2-90B-Vision-Instruct': 'Llama3.2-90B-Vis-Inst',\n",
    "\n",
    "    'google/gemma-2-2b': 'Gemma-2B', 'google/gemma-2-2b-it': 'Gemma-2B-Inst',  'google/gemma-2-9b': 'Gemma-9B', 'google/gemma-2-9b-it': 'Gemma-9B-Inst', \n",
    "    'google/gemma-2-27b': 'Gemma-27B', 'google/gemma-2-27b-it': 'Gemma-27B-Inst', \n",
    "    \n",
    "    \"Qwen/Qwen2.5-0.5B\": \"Qwen-0.5B\", \"Qwen/Qwen2.5-0.5B-Instruct\": \"Qwen-0.5B-Inst\", \"Qwen/Qwen2.5-1.5B\": \"Qwen-1.5B\", \"Qwen/Qwen2.5-1.5B-Instruct\": \"Qwen-1.5B-Inst\", \n",
    "    \"Qwen/Qwen2.5-3B\": \"Qwen-3B\", \"Qwen/Qwen2.5-3B-Instruct\": \"Qwen-3B-Inst\", \"Qwen/Qwen2.5-7B\": \"Qwen-7B\", \"Qwen/Qwen2.5-7B-Instruct\": \"Qwen-7B-Inst\",\n",
    "    \"Qwen/Qwen2.5-14B\": \"Qwen-14B\", \"Qwen/Qwen2.5-14B-Instruct\": \"Qwen-14B-Inst\", \"Qwen/Qwen2.5-32B\": \"Qwen-32B\", \"Qwen/Qwen2.5-32B-Instruct\": \"Qwen-32B-Inst\",\n",
    "    \"Qwen/Qwen2.5-72B\": \"Qwen-72B\", \"Qwen/Qwen2.5-72B-Instruct\": \"Qwen-72B-Inst\", \n",
    "    \n",
    "    'allenai/OLMo-7B-0724-hf_step2000-tokens8B' : 'Olmo-7B-Tokens-8B',\n",
    "    'allenai/OLMo-7B-0724-hf_step26500-tokens111B': 'Olmo-7B-Tokens-111B', \n",
    "    'allenai/OLMo-7B-0724-hf_step106500-tokens446B': 'Olmo-7B-Tokens-446B', \n",
    "    'allenai/OLMo-7B-0724-hf_step143000-tokens599B': 'Olmo-7B-Tokens-599B',\n",
    "    'allenai/OLMo-7B-0724-hf_step330000-tokens1384B': 'Olmo-7B-Tokens-1384B',\n",
    "    'allenai/OLMo-7B-0724-hf_step395000-tokens1656B' : 'Olmo-7B-Tokens-1656B',\n",
    "    'allenai/OLMo-7B-0724-hf_step458000-tokens1920B' : 'Olmo-7B-Tokens-1920B', \n",
    "    'allenai/OLMo-7B-0724-hf_step519000-tokens2176B': 'Olmo-7B-Tokens-2176B',\n",
    "    'allenai/OLMo-7B-0724-hf_step647650-tokens2716B': 'Olmo-7B-Tokens-2716B', 'allenai/OLMo-7B-0724-hf_step650650-tokens2729B': 'Olmo-7B-Tokens-2729B',\n",
    "\n",
    "    'allenai/OLMo-1B-0724-hf_step20000-tokens41B': 'Olmo-1B-Tokens-41B', \n",
    "    'allenai/OLMo-1B-0724-hf_step379000-tokens794B': 'Olmo-1B-Tokens-794B',\n",
    "    'allenai/OLMo-1B-0724-hf_step558000-tokens1169B': 'Olmo-1B-Tokens-1169B',\n",
    "    'allenai/OLMo-1B-0724-hf_step738000-tokens1547B': 'Olmo-1B-Tokens-1547B',\n",
    "    'allenai/OLMo-1B-0724-hf_step917000-tokens1922B': 'Olmo-1B-Tokens-1922B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1038000-tokens2176B': 'Olmo-1B-Tokens-2176B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1128000-tokens2364B': 'Olmo-1B-Tokens-2364B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1308000-tokens2742B': 'Olmo-1B-Tokens-2742B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1399000-tokens2932B': 'Olmo-1B-Tokens-2932B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1454000-tokens3048B': 'Olmo-1B-Tokens-3048B',}\n",
    "\n",
    "\n",
    "performance_df['model'] = performance_df.index\n",
    "model_to_family = {}\n",
    "for family, models in families.items():\n",
    "    for model in models:\n",
    "        model_to_family[model] = family\n",
    "\n",
    "performance_df['Family'] = performance_df.index.map(model_to_family)\n",
    "basic_keys = [\"GPT\", \"Llama-3.2\", \"Gemma-2\", \"Qwen-2.5\", \"OLMo-7b\", \"OLMo-1b\"]\n",
    "performance_df_short = performance_df[performance_df['Family'].isin(basic_keys)]\n",
    "#models = ['google/gemma-2-2b-it', 'meta-llama/Meta-Llama-3-70B', 'lmsys/vicuna-13b-v1.5', 'google/gemma-2-9b', 'Human']\n",
    "\n",
    "\n",
    "filtered_perf = performance_df[performance_df.model.isin(model_mapping_short.keys())]\n",
    "filtered_perf['nicknames'] = filtered_perf.model.map(model_mapping_short)\n",
    "\n",
    "#model_order = ['Humans', 'Gemma-9B', 'Vicuna-13B', \"Gemma-2B-I\", \"Llama3-70B-I\"]\n",
    "# model_order = ['Humans', 'Gemma-9B', \"Llama3-70B\"]\n",
    "\n",
    "sent_type_mapping = {\n",
    "    'GP_prob_GP_question': \"GP-Plaus.\", \n",
    "    'nonGP_prob_GP_question': \"NGP-Plaus.\", \n",
    "    'GP_improb_GP_question': \"GP-Implaus.\", \n",
    "    'nonGP_improb_GP_question': \"NGP-Implaus.\", \n",
    "    'GP_reflexive_GP_question': \"GP-Reflexive\", \n",
    "    'nonGP_reflexive_GP_question': \"NGP-Reflexive\"\n",
    "}\n",
    "\n",
    "sent_type_order = [\"GP-Plaus.\", \"NGP-Plaus.\", \"GP-Implaus.\", \"NGP-Implaus.\", \"GP-Reflexive\", \"NGP-Reflexive\"]\n",
    "\n",
    "\n",
    "def get_model_final_name(series):\n",
    "    if series['Family'] == 'GPT':\n",
    "        return series['nicknames']\n",
    "    elif 'OLMo' in series['Family']:\n",
    "        return series['num_parameters']\n",
    "    else:\n",
    "        return str(series['num_parameters']) + '-Inst' if series['instruction_tuned'] else series['num_parameters']\n",
    "\n",
    "\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "df_melted = filtered_perf.melt(id_vars=['nicknames', 'Family', 'model'], var_name='condition', value_name='performance')\n",
    "df_melted['conds'] = df_melted.condition.map(sent_type_mapping)\n",
    "model_names = df_melted.model.to_list()\n",
    "num_params = [get_model_parameters(name, model_to_family[name]) for name in model_names]\n",
    "df_melted['num_parameters'] = num_params\n",
    "df_melted['instruction_tuned'] = df_melted.model.map(is_instruction_tuned)\n",
    "df_melted['SentenceType'] = df_melted['condition'].map(lambda x: x.split('_')[0])\n",
    "df_melted['Manipulation'] = df_melted['conds'].map(lambda x: x.split('-')[1].replace('.', 'ible'))\n",
    "df_melted['final_name'] = df_melted.apply(get_model_final_name, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = { 'GPT': ['GPT4', 'GPT4-T', 'GPT4-O', 'GPT4-O-M', 'O1-Mini',\n",
    "        'O1-Prev.'],\n",
    "        'Qwen-2.5': [\n",
    "        'Qwen-14B', 'Qwen-32B', 'Qwen-32B-Inst',\n",
    "        'Qwen-72B', 'Qwen-72B-Inst', 'Qwen-7B'],\n",
    " 'Gemma-2': ['Gemma-27B-Inst', 'Gemma-27B', 'Gemma-2B', 'Gemma-2B-Inst',\n",
    "        'Gemma-9B', 'Gemma-9B-Inst'],\n",
    " 'Llama-3.2': ['Llama3.2-11B-Vis', 'Llama3.2-11B-Vis-Inst', 'Llama3.2-1B',\n",
    "        'Llama3.2-3B', 'Llama3.2-90B-Vis', 'Llama3.2-90B-Vis-Inst'],\n",
    " 'OLMo-7b': ['Olmo-7B-Tokens-446B', 'Olmo-7B-Tokens-111B',\n",
    "        'Olmo-7B-Tokens-1384B', 'Olmo-7B-Tokens-2176B',\n",
    "        'Olmo-7B-Tokens-2716B', 'Olmo-7B-Tokens-2729B'],\n",
    " 'OLMo-1b': ['Olmo-1B-Tokens-2176B', 'Olmo-1B-Tokens-2553B',\n",
    "        'Olmo-1B-Tokens-3048B', 'Olmo-1B-Tokens-41B',\n",
    "        'Olmo-1B-Tokens-794B', 'Olmo-1B-Tokens-1169B'],}\n",
    "\n",
    "titles = {'Qwen-2.5': 'Number of Parameters (Billions)', 'OLMo-1b': 'Number of Tokens (Billions)', 'OLMo-7b': 'Number of Tokens (Billions)', 'Gemma-2': 'Number of Parameters (Billions)', 'GPT': 'Model name', 'Llama-3.2': 'Number of Parameters (Billions)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_interest = list()\n",
    "for key in all_models:\n",
    "    all_models_interest.extend(all_models[key])\n",
    "\n",
    "df_melted_interest = df_melted[df_melted.nicknames.isin(all_models_interest)]\n",
    "\n",
    "figures = list()\n",
    "for family, models in all_models.items():\n",
    "    df_family = df_melted[df_melted.Family == family]\n",
    "    df_family['Sentence type'] = df_family['SentenceType']\n",
    "    df_family = df_family[df_family.nicknames.isin(all_models[family])]\n",
    "    df_family = df_family.sort_values(by=['Family', 'num_parameters', 'instruction_tuned'], ascending=[True, True, True])\n",
    "    \n",
    "    fig = px.bar(\n",
    "        df_family,\n",
    "        x='Manipulation',\n",
    "        y='performance',\n",
    "        color='Sentence type',\n",
    "        pattern_shape=\"Sentence type\",\n",
    "        barmode='group',\n",
    "        category_orders={\"Manipulation\": [\"Plausible\", \"Implausible\", \"Reflexive\"]},\n",
    "        color_discrete_sequence=['#E69F00', '#56B4E9'],\n",
    "        facet_col='final_name',\n",
    "        facet_col_spacing=0.025,\n",
    "        labels={'final_name': ''}\n",
    "    )\n",
    "\n",
    "    # Update layout for the custom font and legend\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            family=\"Arial\",\n",
    "            color=\"black\",\n",
    "            size=16\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=-0.67,\n",
    "            xanchor='center',\n",
    "            x=0.5,\n",
    "            font=dict(\n",
    "                family=\"Arial\",\n",
    "                color=\"black\",\n",
    "                size=13\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='Accuracy'),\n",
    "        xaxis_title = titles[family],\n",
    "        template='plotly_white',\n",
    "        width=800,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=family,\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            font=dict(\n",
    "                size=20\n",
    "            ),\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    if family == \"OLMo-1b\":\n",
    "        fig.update_layout(\n",
    "            showlegend=True,\n",
    "            height=400\n",
    "        )\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=16, color=\"black\"), y=-0.43, yanchor='bottom'))\n",
    "        fig.update_xaxes(tickfont=dict(size=16, color=\"black\"), showticklabels = True, title_text=\"\", tickangle=40)\n",
    "    elif family == \"OLMo-7b\":\n",
    "        fig.update_layout(\n",
    "            showlegend=True,\n",
    "            height=400\n",
    "        )\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=16, color=\"black\"), y=-0.43, yanchor='bottom'))\n",
    "        fig.update_xaxes(tickfont=dict(size=16, color=\"black\"), showticklabels = True, title_text=\"\", tickangle=40)\n",
    "    else:\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=16, color=\"black\"), y=-0.14, yanchor='bottom'))\n",
    "        fig.update_xaxes(tickfont=dict(size=16, color=\"black\"), showticklabels = False, title_text=\"\", tickangle=70)\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=0.5,\n",
    "        y=-0.15 if (family != \"OLMo-1b\" and family != \"OLMo-7b\") else -0.45,\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        showarrow=False,\n",
    "        text=titles[family],\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(size=16)\n",
    "    )\n",
    "\n",
    "    figures.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Parameters\n",
    "fig_height = 300\n",
    "fig_width = 800\n",
    "shared_section_height = 35\n",
    "\n",
    "# Save each figure as a PNG image\n",
    "for idx, fig in enumerate(figures):\n",
    "    if idx < len(figures) - 2:\n",
    "        fig.write_image(f\"/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/temp_files/figure_{idx}.png\", width=800, height=300)\n",
    "    else:\n",
    "        fig.write_image(f\"/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/temp_files/figure_{idx}.png\", width=800, height=400)\n",
    "\n",
    "# Adjusted images array with shared section placeholder\n",
    "images = []\n",
    "for idx in range(len(figures)):\n",
    "    img = Image.open(f\"/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/temp_files/figure_{idx}.png\")\n",
    "    images.append(img)\n",
    "\n",
    "# Create the shared section\n",
    "shared_img = images[-2].crop((0, images[-2].height - shared_section_height, fig_width, images[-2].height))\n",
    "blank_img = images[-2].crop((0, images[-1].height -35, 250, images[-1].height))\n",
    "\n",
    "# Calculate necessary dimensions for the final combined image\n",
    "cols = 2\n",
    "rows = (len(images) + (cols - 1)) // cols\n",
    "max_width = fig_width * cols\n",
    "max_height = (300 * 2 + 400) - shared_section_height\n",
    "\n",
    "# Create a new blank image with the combined dimensions\n",
    "combined_image = Image.new('RGB', (max_width, max_height + shared_section_height), color='white')\n",
    "\n",
    "# Paste each image onto the combined image\n",
    "y_offset = 0\n",
    "for row in range(rows):\n",
    "    x_offset = 0\n",
    "    for col in range(cols):\n",
    "        idx = row * cols + col\n",
    "        if idx < len(images):\n",
    "            combined_image.paste(images[idx], (x_offset, y_offset))\n",
    "            x_offset += fig_width\n",
    "    y_offset += 300 if row < rows - 1 else 400\n",
    "\n",
    "combined_image.paste(blank_img, (250, 962))\n",
    "combined_image.paste(blank_img, (1050, 962))\n",
    "combined_image.paste(blank_img, (1250, 962))\n",
    "combined_image.paste(shared_img, (400, 962))\n",
    "\n",
    "# (Optional) Save the combined image as PDF\n",
    "combined_image.save('/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/experiments/gardenpath_10_24/analysis/plots/combined_image.pdf', \"PDF\", resolution=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "df = pd.read_csv('experiments/gardenpath_10_24/results/llm_results/rephrasing_all_results.csv')\n",
    "df_data = pd.read_csv('experiments/gardenpath_10_24/data/llm_data/rephrasing_experiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_verb(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    look_first = True if sentence[:5] == \"While\" else False\n",
    "    found_first = False\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'VERB':\n",
    "            if look_first:\n",
    "                return token.lemma_\n",
    "            else:\n",
    "                if found_first:\n",
    "                    return token.lemma_\n",
    "                found_first = True\n",
    "    return \"swing\"\n",
    "\n",
    "\n",
    "def find_noun(sentence):\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    look_first = False if sentence[:5] == \"While\" else True\n",
    "    found_first = False\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'NOUN' or token.pos_ == 'PROPN':\n",
    "            if look_first:\n",
    "                return token.lemma_\n",
    "            else:\n",
    "                if found_first:\n",
    "                    return token.lemma_\n",
    "                found_first = True\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['verb'] = df_data['sentence'].map(find_verb)\n",
    "df_data['noun'] = df_data['sentence'].map(find_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = df_data['noun'].to_list()\n",
    "sentences = df_data['sentence'].to_list()\n",
    "noun_mappings = dict()\n",
    "for i in range(len(nouns)):\n",
    "    noun_mappings[sentences[i]] = nouns[i]\n",
    "\n",
    "verbs = df_data['verb'].to_list()\n",
    "verb_mappings = dict()\n",
    "for i in range(len(verbs)):\n",
    "    verb_mappings[sentences[i]] = verbs[i]\n",
    "\n",
    "\n",
    "small_df = df_llm[df_llm.model == 'gpt-4']\n",
    "sentences = small_df.sentence.to_list()\n",
    "sent_types = small_df.sent_type.to_list()\n",
    "sent_maps = dict()\n",
    "for i in range(len(sentences)):\n",
    "    sent_maps[sentences[i]] = sent_types[i]\n",
    "\n",
    "df['noun'] = df['sentence'].map(noun_mappings)\n",
    "df['verb'] = df['sentence'].map(verb_mappings)\n",
    "df['sent_type'] = df['sentence'].map(sent_maps)\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(output_txt):\n",
    "    lines = output_txt.split('\\n')\n",
    "    if lines[0].strip() == \"Splitted:\":\n",
    "        lines = lines[1:]\n",
    "    s1 = lines[0].split('1. ')[-1].split('. ')[0] + '.'\n",
    "    s2 = lines[1].split('2. ')[-1].split('. ')[0] + '.'\n",
    "    return [s1.replace('..', '.'), s2.replace('..', '.')]\n",
    "\n",
    "\n",
    "def check_sentences(sentences, verb, noun):\n",
    "\n",
    "    correct, found = False, False\n",
    "    for sent in sentences:\n",
    "        doc = nlp(sent)\n",
    "        for token in doc:\n",
    "            if token.lemma_ == verb or token.lemma_ == \"swung\" or token.lemma_ == \"parking\":\n",
    "                found = True\n",
    "                if noun not in sent:\n",
    "                    correct = True\n",
    "                    \n",
    "    return found, correct\n",
    "\n",
    "\n",
    "founds, corrects, formatteds = [], [], []\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        found, correct = check_sentences(get_predictions(df['txt'].iloc[i]), df['verb'].iloc[i], df['noun'].iloc[i])\n",
    "        formatted = True\n",
    "    except:\n",
    "        found, correct = False, False\n",
    "        formatted = False\n",
    "    founds.append(found)\n",
    "    corrects.append(correct)\n",
    "    formatteds.append(formatted)\n",
    "\n",
    "df['found'] = founds\n",
    "df['gp_correct'] = corrects\n",
    "df['formatted'] = formatteds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "['meta-llama/Llama-2-7b-chat-hf', 'meta-llama/Llama-2-13b-chat-hf', 'Qwen/Qwen2.5-1.5B', 'Qwen/Qwen2.5-3B', 'lmsys/vicuna-13b-v1.5', 'lmsys/vicuna-7b-v1.5']\n"
     ]
    }
   ],
   "source": [
    "to_drop = list()\n",
    "for mod in df.model.unique():\n",
    "    model_data = df[df.model == mod]\n",
    "    if model_data.found.mean() < 0.9 or model_data.formatted.mean() < 0.9:\n",
    "        to_drop.append(mod)\n",
    "\n",
    "df_dropped = df[~df.model.isin(to_drop)]\n",
    "print(len(to_drop))\n",
    "print(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_performance = df_dropped.groupby(['model', 'sent_type'])['gp_correct'].mean().reset_index()\n",
    "paraphrase_performance_df = llm_performance.pivot(index='model', columns='sent_type', values='gp_correct')\n",
    "\n",
    "model_mapping_short = {\n",
    "    \"gpt-4\": \"GPT4\", \"gpt-4-turbo\": \"GPT4-T\", \"gpt-4o\": \"GPT4-O\", \"gpt-4o-mini\": \"GPT4-O-M\", \"o1-mini\": \"O1-Mini\", \"o1-preview\": \"O1-Prev.\",\n",
    "\n",
    "    'meta-llama/Llama-3.2-1B': 'Llama3.2-1B', 'meta-llama/Llama-3.2-1B-Instruct': 'Llama3.2-1B-Inst',\n",
    "    'meta-llama/Llama-3.2-3B': 'Llama3.2-3B', 'meta-llama/Llama-3.2-3B-Instruct': 'Llama3.2-3B-Inst', 'meta-llama/Llama-3.2-11B-Vision': 'Llama3.2-11B-Vis', \n",
    "    'meta-llama/Llama-3.2-11B-Vision-Instruct': 'Llama3.2-11B-Vis-Inst', 'meta-llama/Llama-3.2-90B-Vision': 'Llama3.2-90B-Vis',\n",
    "    'meta-llama/Llama-3.2-90B-Vision-Instruct': 'Llama3.2-90B-Vis-Inst',\n",
    "\n",
    "    'google/gemma-2-2b': 'Gemma-2B', 'google/gemma-2-2b-it': 'Gemma-2B-Inst',  'google/gemma-2-9b': 'Gemma-9B', 'google/gemma-2-9b-it': 'Gemma-9B-Inst', \n",
    "    'google/gemma-2-27b': 'Gemma-27B', 'google/gemma-2-27b-it': 'Gemma-27B-Inst', \n",
    "    \n",
    "    \"Qwen/Qwen2.5-0.5B\": \"Qwen-0.5B\", \"Qwen/Qwen2.5-0.5B-Instruct\": \"Qwen-0.5B-Inst\", \"Qwen/Qwen2.5-1.5B\": \"Qwen-1.5B\", \"Qwen/Qwen2.5-1.5B-Instruct\": \"Qwen-1.5B-Inst\", \n",
    "    \"Qwen/Qwen2.5-3B\": \"Qwen-3B\", \"Qwen/Qwen2.5-3B-Instruct\": \"Qwen-3B-Inst\", \"Qwen/Qwen2.5-7B\": \"Qwen-7B\", \"Qwen/Qwen2.5-7B-Instruct\": \"Qwen-7B-Inst\",\n",
    "    \"Qwen/Qwen2.5-14B\": \"Qwen-14B\", \"Qwen/Qwen2.5-14B-Instruct\": \"Qwen-14B-Inst\", \"Qwen/Qwen2.5-32B\": \"Qwen-32B\", \"Qwen/Qwen2.5-32B-Instruct\": \"Qwen-32B-Inst\",\n",
    "    \"Qwen/Qwen2.5-72B\": \"Qwen-72B\", \"Qwen/Qwen2.5-72B-Instruct\": \"Qwen-72B-Inst\", \n",
    "    \n",
    "    'allenai/OLMo-7B-0724-hf_step26500-tokens111B': 'Olmo-7B-Tokens-111B', \n",
    "    'allenai/OLMo-7B-0724-hf_step106500-tokens446B': 'Olmo-7B-Tokens-446B', \n",
    "    'allenai/OLMo-7B-0724-hf_step330000-tokens1384B': 'Olmo-7B-Tokens-1384B', \n",
    "    'allenai/OLMo-7B-0724-hf_step519000-tokens2176B': 'Olmo-7B-Tokens-2176B',\n",
    "    'allenai/OLMo-7B-0724-hf_step647650-tokens2716B': 'Olmo-7B-Tokens-2716B', 'allenai/OLMo-7B-0724-hf_step650650-tokens2729B': 'Olmo-7B-Tokens-2729B',\n",
    "    \n",
    "    'allenai/OLMo-1B-0724-hf_step20000-tokens41B': 'Olmo-1B-Tokens-41B', \n",
    "    'allenai/OLMo-1B-0724-hf_step379000-tokens794B': 'Olmo-1B-Tokens-794B',\n",
    "    'allenai/OLMo-1B-0724-hf_step558000-tokens1169B': 'Olmo-1B-Tokens-1169B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1038000-tokens2176B': 'Olmo-1B-Tokens-2176B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1218000-tokens2553B': 'Olmo-1B-Tokens-2553B',\n",
    "    'allenai/OLMo-1B-0724-hf_step1454000-tokens3048B': 'Olmo-1B-Tokens-3048B',}\n",
    "\n",
    "\n",
    "paraphrase_performance_df['model'] = paraphrase_performance_df.index\n",
    "\n",
    "model_to_family = {}\n",
    "for family, models in families.items():\n",
    "    for model in models:\n",
    "        model_to_family[model] = family\n",
    "\n",
    "paraphrase_performance_df['Family'] = paraphrase_performance_df.index.map(model_to_family)\n",
    "basic_keys = [\"GPT\", \"Llama-3.2\", \"Gemma-2\", \"Qwen-2.5\"]\n",
    "paraphrase_performance_df_short = paraphrase_performance_df[paraphrase_performance_df['Family'].isin(basic_keys)]\n",
    "#models = ['google/gemma-2-2b-it', 'meta-llama/Meta-Llama-3-70B', 'lmsys/vicuna-13b-v1.5', 'google/gemma-2-9b', 'Human']\n",
    "\n",
    "\n",
    "paraphrase_filtered_perf = paraphrase_performance_df[paraphrase_performance_df.model.isin(model_mapping_short.keys())]\n",
    "paraphrase_filtered_perf['nicknames'] = paraphrase_filtered_perf.model.map(model_mapping_short)\n",
    "\n",
    "#model_order = ['Humans', 'Gemma-9B', 'Vicuna-13B', \"Gemma-2B-I\", \"Llama3-70B-I\"]\n",
    "# model_order = ['Humans', 'Gemma-9B', \"Llama3-70B\"]\n",
    "\n",
    "sent_type_mapping = {\n",
    "    'GP_prob': \"GP-Plaus.\", \n",
    "    'nonGP_prob': \"NGP-Plaus.\", \n",
    "    'GP_improb': \"GP-Implaus.\", \n",
    "    'nonGP_improb': \"NGP-Implaus.\", \n",
    "    'GP_reflexive': \"GP-Reflexive\", \n",
    "    'nonGP_reflexive': \"NGP-Reflexive\"\n",
    "}\n",
    "\n",
    "sent_type_order = [\"GP-Plaus.\", \"NGP-Plaus.\", \"GP-Implaus.\", \"NGP-Implaus.\", \"GP-Reflexive\", \"NGP-Reflexive\"]\n",
    "\n",
    "\n",
    "def get_model_final_name(series):\n",
    "    if series['Family'] == 'GPT':\n",
    "        return series['nicknames']\n",
    "    elif 'OLMo' in series['Family']:\n",
    "        return series['num_parameters']\n",
    "    else:\n",
    "        return str(series['num_parameters']) + '-Inst' if series['instruction_tuned'] else series['num_parameters']\n",
    "\n",
    "\n",
    "\n",
    "# Melt the DataFrame to long format\n",
    "paraphrase_df_melted = paraphrase_filtered_perf.melt(id_vars=['nicknames', 'Family', 'model'], var_name='sent_type', value_name='performance')\n",
    "paraphrase_df_melted['conds'] = paraphrase_df_melted.sent_type.map(sent_type_mapping)\n",
    "paraphrase_model_names = paraphrase_df_melted.model.to_list()\n",
    "paraphrase_num_params = [get_model_parameters(name, model_to_family[name]) for name in paraphrase_model_names]\n",
    "paraphrase_df_melted['num_parameters'] = paraphrase_num_params\n",
    "paraphrase_df_melted['instruction_tuned'] = paraphrase_df_melted.model.map(is_instruction_tuned)\n",
    "paraphrase_df_melted['SentenceType'] = paraphrase_df_melted['sent_type'].map(lambda x: x.split('_')[0])\n",
    "paraphrase_df_melted['Manipulation'] = paraphrase_df_melted['conds'].map(lambda x: x.split('-')[1].replace('.', 'ible'))\n",
    "paraphrase_df_melted['final_name'] = paraphrase_df_melted.apply(get_model_final_name, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = { 'GPT': ['GPT4', 'GPT4-T', 'GPT4-O', 'GPT4-O-M', 'O1-Mini',\n",
    "        'O1-Prev.'],\n",
    "        'Qwen-2.5': [\n",
    "        'Qwen-14B', 'Qwen-32B', 'Qwen-32B-Inst',\n",
    "        'Qwen-72B', 'Qwen-72B-Inst', 'Qwen-7B'],\n",
    " 'Gemma-2': ['Gemma-27B-Inst', 'Gemma-2B', 'Gemma-2B-Inst',\n",
    "        'Gemma-9B', 'Gemma-9B-Inst'],\n",
    " 'Llama-3.2': ['Llama3.2-11B-Vis', 'Llama3.2-11B-Vis-Inst', 'Llama3.2-1B',\n",
    "        'Llama3.2-3B', 'Llama3.2-90B-Vis', 'Llama3.2-90B-Vis-Inst'],}\n",
    "\n",
    "titles = {'Qwen-2.5': 'Number of Parameters (Billions)', 'OLMo-1b': 'Number of Tokens (Billions)', 'OLMo-7b': 'Number of Tokens (Billions)', 'Gemma-2': 'Number of Parameters (Billions)', 'GPT': 'Model name', 'Llama-3.2': 'Number of Parameters (Billions)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_interest = list()\n",
    "for key in all_models:\n",
    "    all_models_interest.extend(all_models[key])\n",
    "\n",
    "paraphrase_df_melted_interest = paraphrase_df_melted[paraphrase_df_melted.nicknames.isin(all_models_interest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures = list()\n",
    "for family, models in all_models.items():\n",
    "    paraphrase_df_family = paraphrase_df_melted[paraphrase_df_melted.Family == family]\n",
    "    paraphrase_df_family = paraphrase_df_family[paraphrase_df_family.nicknames.isin(all_models[family])]\n",
    "    paraphrase_df_family = paraphrase_df_family.sort_values(by=['Family', 'num_parameters', 'instruction_tuned'], ascending=[True, True, True])\n",
    "    \n",
    "    fig = px.bar(\n",
    "        paraphrase_df_family,\n",
    "        x='Manipulation',\n",
    "        y='performance',\n",
    "        color='SentenceType',\n",
    "        pattern_shape=\"SentenceType\",\n",
    "        barmode='group',\n",
    "        category_orders={\"Manipulation\": [\"Plausible\", \"Implausible\", \"Reflexive\"]},\n",
    "        color_discrete_sequence=['#E69F00', '#56B4E9'],\n",
    "        facet_col='final_name',\n",
    "        facet_col_spacing=0.025,\n",
    "        labels={'final_name': ''}\n",
    "    )\n",
    "\n",
    "    # Update layout for the custom font and legend\n",
    "    fig.update_layout(\n",
    "        font=dict(\n",
    "            family=\"Arial\",\n",
    "            color=\"black\",\n",
    "            size=16\n",
    "        ),\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            yanchor='bottom',\n",
    "            y=-0.61,\n",
    "            xanchor='center',\n",
    "            x=0.5,\n",
    "            font=dict(\n",
    "                family=\"Arial\",\n",
    "                color=\"black\",\n",
    "                size=13\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='Accuracy'),\n",
    "        xaxis_title = titles[family],\n",
    "        template='plotly_white',\n",
    "        width=800,\n",
    "        height=300\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(range=[0, 1], tickvals=[i * 0.1 for i in range(11)], tickfont=dict(size=16, color=\"black\"))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=dict(\n",
    "            text=family,\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            font=dict(\n",
    "                size=20\n",
    "            ),\n",
    "        ),\n",
    "        showlegend=False\n",
    "    )\n",
    "\n",
    "    if family == \"Llama-3.2\":\n",
    "        fig.update_layout(\n",
    "            showlegend=True,\n",
    "            height=400\n",
    "        )\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=16, color=\"black\"), y=-0.37, yanchor='bottom'))\n",
    "        fig.update_xaxes(tickfont=dict(size=16, color=\"black\"), showticklabels = True, title_text=\"\", tickangle=40)\n",
    "    elif family == \"Gemma-2\":\n",
    "        fig.update_layout(\n",
    "            showlegend=True,\n",
    "            height=400\n",
    "        )\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=16, color=\"black\"), y=-0.37, yanchor='bottom'))\n",
    "        fig.update_xaxes(tickfont=dict(size=16, color=\"black\"), showticklabels = True, title_text=\"\", tickangle=40)\n",
    "    else:\n",
    "        fig.for_each_annotation(lambda a: a.update(text=a.text.split('=')[1], font=dict(size=16, color=\"black\"), y=-0.14, yanchor='bottom'))\n",
    "        fig.update_xaxes(tickfont=dict(size=16, color=\"black\"), showticklabels = False, title_text=\"\", tickangle=70)\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        x=0.5,\n",
    "        y=-0.15 if (family != \"Gemma-2\" and family != \"Llama-3.2\") else -0.38,\n",
    "        xref='paper',\n",
    "        yref='paper',\n",
    "        showarrow=False,\n",
    "        text=titles[family],\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(size=16)\n",
    "    )\n",
    "\n",
    "    figures.append(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Parameters\n",
    "fig_height = 300\n",
    "fig_width = 800\n",
    "shared_section_height = 35\n",
    "\n",
    "# Save each figure as a PNG image\n",
    "for idx, fig in enumerate(figures):\n",
    "    if idx < len(figures) - 2:\n",
    "        fig.write_image(f\"/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/temp_files/paraphrase_figure_{idx}.png\", width=800, height=300)\n",
    "    else:\n",
    "        fig.write_image(f\"/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/temp_files/paraphrase_figure_{idx}.png\", width=800, height=400)\n",
    "\n",
    "# Adjusted images array with shared section placeholder\n",
    "images = []\n",
    "for idx in range(len(figures)):\n",
    "    img = Image.open(f\"/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/temp_files/paraphrase_figure_{idx}.png\")\n",
    "    images.append(img)\n",
    "\n",
    "# Create the shared section\n",
    "shared_img = images[-2].crop((0, images[-2].height - shared_section_height, fig_width, images[-2].height))\n",
    "blank_img = images[-2].crop((0, images[-1].height -35, 250, images[-1].height))\n",
    "\n",
    "# Calculate necessary dimensions for the final combined image\n",
    "cols = 2\n",
    "rows = (len(images) + (cols - 1)) // cols\n",
    "max_width = fig_width * cols\n",
    "max_height = (300 + 400) - shared_section_height\n",
    "\n",
    "# Create a new blank image with the combined dimensions\n",
    "combined_image = Image.new('RGB', (max_width, max_height + shared_section_height), color='white')\n",
    "\n",
    "# Paste each image onto the combined image\n",
    "y_offset = 0\n",
    "for row in range(rows):\n",
    "    x_offset = 0\n",
    "    for col in range(cols):\n",
    "        idx = row * cols + col\n",
    "        if idx < len(images):\n",
    "            combined_image.paste(images[idx], (x_offset, y_offset))\n",
    "            x_offset += fig_width\n",
    "    y_offset += 300 if row < rows - 1 else 400\n",
    "\n",
    "combined_image.paste(blank_img, (250, 662))\n",
    "combined_image.paste(blank_img, (1050, 662))\n",
    "combined_image.paste(blank_img, (1250, 662))\n",
    "combined_image.paste(shared_img, (400, 662))\n",
    "\n",
    "# (Optional) Save the combined image as PDF\n",
    "combined_image.save('/Users/samuelamouyal/PycharmProjects/reading_comprehension_research/experiments/gardenpath_10_24/analysis/plots/combined_paraphrase_image.pdf', \"PDF\", resolution=100.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_nlp_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
